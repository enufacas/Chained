# ğŸ¯ Mission Prompt Evolution Options

## ğŸ“Š Current State Analysis

### The Problem
The autonomous pipeline's mission prompts (`tools/create_mission_issues.py`) currently treat **ALL missions as external learning tasks**, even when work could directly improve Chained's core ecosystem.

**Current prompt characteristics:**
- Generic "investigate and gather insights" instructions
- Focus on exploration and documentation
- No clear connection to improving Chained itself
- Same template for all mission types

### The Balance Challenge

You identified a critical tension:
> "There is a line between learning and building semi related features versus building features more strongly within our core ecosystem"

### Mission Type Examples

**ğŸ§  LEARNING Mission (External Focus):**
- "Explore cloud trends from tech news"
- "Investigate new AI frameworks mentioned in HN"
- Goal: Understand what's happening in the tech world

**ğŸ”§ SEMI-RELATED Mission (Tangential):**
- "Build a cloud deployment tool" (inspired by trends)
- "Create an AI benchmarking system" (inspired by news)
- Goal: Build something related to learnings, but not core to Chained

**âš¡ CORE ECOSYSTEM Mission (Internal Focus):**
- "Improve agent spawning algorithm diversity"
- "Enhance world model geographic accuracy"
- "Optimize autonomous pipeline PR merge timing"
- Goal: Make Chained itself better, stronger, more capable

**Core Ecosystem Components:**
- ğŸ¤– Agent system (spawning, evaluation, competition)
- ğŸ§  Learning system (from external sources)
- ğŸŒ World model (geographic mapping, state)
- ğŸ”„ Autonomous pipeline (workflows, PR creation/merge)
- ğŸ“Š Self-documentation and metrics
- ğŸ† Performance tracking and Hall of Fame

---

## ğŸ¨ Five Evolution Options

### Option 1: Dual-Track Mission System ğŸ”„

**Concept:** Create two distinct mission types with different prompts.

**Learning Track:**
```markdown
## ğŸ§  Learning Mission: {title}
**Type:** External Exploration
- Research and document tech trends
- Identify potential applications to Chained
- Deliverable: Learning report + ecosystem suggestions
```

**Ecosystem Track:**
```markdown
## âš™ï¸ Ecosystem Mission: {title}
**Type:** Core System Enhancement
- Implement direct improvements to Chained
- Deliverable: Code, tests, documentation, metrics
```

**Balance:** Set quotas (e.g., 70% learning / 30% ecosystem)

**Pros:**
- âœ… Clear separation of concerns
- âœ… Agents know exactly what to expect
- âœ… Easy to balance (track mission counts)
- âœ… Can enforce quotas

**Cons:**
- âŒ Requires upfront idea classification
- âŒ More complex routing
- âŒ Less connection between learning and building

**Implementation Effort:** Medium (~250 lines)

---

### Option 2: Graduated Mission System ğŸ“ˆ

**Concept:** Three-level progression from learning to integration.

**Levels:**
1. **Level 1 - Explore:** Research and learn (all missions start here)
2. **Level 2 - Apply:** Build proof-of-concept (if relevance â‰¥ 7)
3. **Level 3 - Integrate:** Merge into core (if integration score â‰¥ 7)

**Pros:**
- âœ… Natural progression
- âœ… Self-regulating (only good ideas advance)
- âœ… Agents see full journey

**Cons:**
- âŒ Longer time to ecosystem improvements
- âŒ Complex state tracking
- âŒ Might lose momentum between levels

**Implementation Effort:** High (~400 lines)

---

### Option 3: Context-Aware Prompt Enhancement ğŸ¯

**Concept:** Single mission type with ecosystem relevance scoring.

**Enhanced Prompt:**
```markdown
## ğŸ¯ Agent Mission: {title}
**Type:** {Learning | Ecosystem}
**Ecosystem Relevance:** {Low | Medium | High | Critical}

{IF High/Critical:}
  Ecosystem Connection: Could improve {components}
  Expected: Implementation + tests + metrics
  
{ELSE:}
  Focus: External learning
  Expected: Research report + insights
```

**Pros:**
- âœ… Single mission system (simpler)
- âœ… Clear communication of intent
- âœ… Easy to implement
- âœ… Flexible expectations

**Cons:**
- âŒ Still need relevance scoring logic
- âŒ Variable expectations might confuse
- âŒ Harder to enforce balance

**Implementation Effort:** Low (~100 lines) â­ EASIEST

---

### Option 4: Explicit Quota Balancing System âš–ï¸

**Concept:** Add metadata to categorize missions and enforce quotas.

**Mission Categories:**
- ğŸ§  Learning: 60%
- âš™ï¸ Ecosystem: 30%
- ğŸ”§ Tool Building: 10%

**Enhanced Prompt:**
```markdown
## {icon} {category} Mission: {title}
**Category:** {Learning | Ecosystem | Tools}
**Quarter Goal:** Learning: 60% | Ecosystem: 30% | Tools: 10%
**Balance Status:** Need {X} more ecosystem missions this quarter
```

**Pros:**
- âœ… Enforced balance automatically
- âœ… Transparent quotas
- âœ… Agents see bigger picture
- âœ… Easy to adjust ratios

**Cons:**
- âŒ Requires classification logic
- âŒ Might constrain good ideas artificially
- âŒ Quota system could feel rigid

**Implementation Effort:** Medium (~250 lines)

---

### Option 5: Two-Phase Learning â†’ Ecosystem Pipeline ğŸ”„ğŸ”§ â­ RECOMMENDED

**Concept:** All missions start as learning, valuable ones auto-generate ecosystem follow-ups.

**Phase 1 - Learning (All missions):**
```markdown
## ğŸ§  Phase 1: Learn About {topic}
**Phase:** 1 of 2 (Exploration)

### Required Deliverables:
- Learning report
- **Ecosystem relevance score (1-10)**
- Integration suggestions (if relevant)

### Phase 2 Trigger:
Score â‰¥ 7 â†’ Automatically creates ecosystem mission
```

**Phase 2 - Ecosystem (Auto-generated for high scores):**
```markdown
## âš¡ Phase 2: Integrate {topic} into Chained
**Phase:** 2 of 2 (Integration)
**Triggered by:** Phase 1 score of {X}/10

### Context from Phase 1:
{Key learnings and insights}

### Implementation Requirements:
- Core system integration
- Tests and validation
- Performance measurement
```

**Pros:**
- âœ… Best of both worlds (learning + building)
- âœ… Natural progression for valuable ideas
- âœ… Clear connection between phases
- âœ… Quality filtering (only good ideas â†’ core)
- âœ… Agent ownership (same agent both phases)
- âœ… Preserves learning strength

**Cons:**
- âŒ More complex pipeline
- âŒ Need scoring mechanism
- âŒ Two prompt templates

**Balance:** ~30% of missions reach Phase 2 (emergent from quality)

**Implementation Effort:** Medium (~300 lines)

---

## ğŸ“Š Comparison Matrix

| Option | Complexity | Balance Control | Agent Clarity | Effort | Learning Preserved |
|--------|------------|-----------------|---------------|--------|-------------------|
| 1. Dual-Track | Medium | High (Quotas) | Excellent | Medium | Separate |
| 2. Graduated | High | Self-regulating | Good | High | Yes |
| 3. Context-Aware | Low | Medium | Good | Low â­ | Yes |
| 4. Quota System | Medium | Excellent | Excellent | Medium | Yes |
| 5. Two-Phase â­ | Medium | Natural | Excellent | Medium | Yes + Enhanced |

---

## ğŸ’¡ My Recommendation: Option 5 (Two-Phase Pipeline)

### Why Option 5?

1. **Preserves your learning strength** - All missions start as learning
2. **Natural progression** - Agents learn first, then build
3. **Quality filtering** - Only valuable findings reach ecosystem phase
4. **Clear connection** - Phase 2 explicitly references Phase 1 learnings
5. **Balanced automatically** - ~30% reach Phase 2 (emergent from quality)
6. **Agent ownership** - Same agent completes both phases
7. **Minimal disruption** - Builds on existing flow

### Implementation Overview

**Step 1: Update mission creation**
- All missions labeled as "Phase 1 - Learning"
- Add ecosystem scoring requirement
- Template emphasizes research + evaluation

**Step 2: Add Phase 2 generation**
- On Phase 1 completion, check score
- If score â‰¥ 7: Auto-generate Phase 2 mission
- Phase 2 inherits context from Phase 1
- Assign to same agent

**Step 3: Track metrics**
- Phase 1 completion rate
- Phase 2 trigger rate (target ~30%)
- Ecosystem improvement velocity

**Changes Required:**
1. `tools/create_mission_issues.py` - Two prompt templates
2. New script: `tools/generate_phase2_mission.py`
3. Workflow trigger for Phase 2 generation
4. Mission data: Add phase and scoring fields

---

## ğŸ¤” Discussion Questions

Before implementing, I'd like your input on:

1. **Which option resonates with you most?**
   - Option 5 (Two-Phase) is my recommendation
   - But Option 3 (Context-Aware) is simplest
   - Or do you prefer a different approach?

2. **What's your target balance?**
   - How much should be learning vs ecosystem?
   - 70/30? 80/20? Let it emerge naturally?

3. **Scoring threshold?**
   - For Phase 2 trigger, is 7/10 right?
   - Should it be higher (8/10) or lower (6/10)?

4. **Should we pilot with one option first?**
   - Test with 5-10 missions before full rollout?
   - Or implement system-wide immediately?

5. **Any other considerations?**
   - Other mission types to consider?
   - Different categorization needed?

---

## ğŸš€ Next Steps

Once you choose an option, I'll:

1. âœ… Implement the chosen approach
2. âœ… Update prompt templates
3. âœ… Modify mission creation logic
4. âœ… Add any necessary tracking
5. âœ… Update documentation
6. âœ… Test with sample missions
7. âœ… Create PR with changes

Let me know which direction you'd like to go!

---

## ğŸ“ Detailed Examples

See complete prompt examples in `/tmp/prompt_examples.md` (local) showing:
- Current baseline prompt
- Option 3 enhanced prompt
- Option 5 Phase 1 and Phase 2 prompts
- Option 1 dual-track prompts

**Quick Preview - Option 5 Phase 1:**
```markdown
## ğŸ§  Phase 1: Learn About Cloud Innovation

**Phase:** 1 of 2 (Exploration)
**Type:** Learning Mission

### ğŸ“ Learning Objective
Research cloud security trends from tech news...

### ğŸ“Š Phase 1 Deliverables
- [ ] Learning Report (1-2 pages)
- [ ] Ecosystem Applicability Assessment (1-10 score)
- [ ] Phase 2 Recommendation (Yes/No + proposal)

### âš¡ Phase 2 Trigger
Score â‰¥ 7/10 â†’ Auto-creates integration mission
```

**Option 5 Phase 2 (Auto-generated):**
```markdown
## âš¡ Phase 2: Integrate Cloud Security into Chained

**Phase:** 2 of 2 (Ecosystem Integration)
**Triggered by:** Phase 1 score of 8/10

### ğŸ”— Context from Phase 1
{Summary of Phase 1 learnings}

### ğŸ¯ Integration Objective
Apply learnings to enhance Chained's {component}...

### ğŸ“Š Deliverables
- [ ] Implementation with tests
- [ ] Documentation updates
- [ ] Performance measurement
```

---

*Created: 2025-11-16*
*Issue: Improving autonomous pipeline mission prompts*
*Goal: Balance learning vs core ecosystem building*
