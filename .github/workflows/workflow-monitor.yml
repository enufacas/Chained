name: Workflow Monitor and Self-Healing

on:
  schedule:
    # Run twice daily to monitor workflow health
    - cron: '0 */12 * * *'
  workflow_dispatch:

permissions:
  contents: read
  issues: write
  actions: read

jobs:
  monitor-workflows:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Monitor workflow health
        id: monitor
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üîç Monitoring workflow health..."
          echo ""
          
          # Get workflow runs from the last 24 hours
          runs_json=$(gh run list --limit 100 --json databaseId,name,status,conclusion,createdAt,displayTitle)
          
          # Count failures
          total_runs=$(echo "$runs_json" | jq '. | length')
          failed_runs=$(echo "$runs_json" | jq '[.[] | select(.conclusion == "failure")] | length')
          cancelled_runs=$(echo "$runs_json" | jq '[.[] | select(.conclusion == "cancelled")] | length')
          success_runs=$(echo "$runs_json" | jq '[.[] | select(.conclusion == "success")] | length')
          
          echo "Total runs (last 100): $total_runs"
          echo "Failed: $failed_runs"
          echo "Cancelled: $cancelled_runs"
          echo "Successful: $success_runs"
          echo ""
          
          # Calculate failure rate
          if [ "$total_runs" -gt 0 ]; then
            failure_rate=$(awk "BEGIN {printf \"%.1f\", ($failed_runs/$total_runs)*100}")
          else
            failure_rate="0.0"
          fi
          
          echo "Failure rate: ${failure_rate}%"
          echo ""
          
          # Check critical workflows
          echo "Checking critical workflows..."
          critical_workflows=(
            "learn-from-tldr.yml"
            "learn-from-hackernews.yml"
            "idea-generator.yml"
            "smart-idea-generator.yml"
            "issue-to-pr.yml"
            "auto-review-merge.yml"
            "timeline-updater.yml"
          )
          
          failed_critical=""
          for workflow in "${critical_workflows[@]}"; do
            workflow_name=$(echo "$workflow" | sed 's/.yml//' | sed 's/-/ /g' | sed 's/\b\(.\)/\u\1/g')
            recent_status=$(echo "$runs_json" | jq -r ".[] | select(.name | contains(\"$workflow_name\")) | .conclusion" | head -1)
            
            if [ "$recent_status" = "failure" ]; then
              echo "‚ùå $workflow - FAILED"
              failed_critical="$failed_critical\n- $workflow_name"
            elif [ "$recent_status" = "success" ]; then
              echo "‚úÖ $workflow - OK"
            else
              echo "‚ö†Ô∏è  $workflow - No recent runs"
            fi
          done
          
          # Set outputs
          echo "failure_rate=${failure_rate}" >> $GITHUB_OUTPUT
          echo "failed_runs=${failed_runs}" >> $GITHUB_OUTPUT
          echo "total_runs=${total_runs}" >> $GITHUB_OUTPUT
          
          if [ -n "$failed_critical" ]; then
            echo "has_critical_failures=true" >> $GITHUB_OUTPUT
            echo "failed_workflows<<EOF" >> $GITHUB_OUTPUT
            echo -e "$failed_critical" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "has_critical_failures=false" >> $GITHUB_OUTPUT
          fi

      - name: Analyze failure patterns
        id: analyze
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üìä Analyzing failure patterns..."
          echo ""
          
          # Get failed workflow runs
          failed_runs=$(gh run list --limit 50 --json databaseId,name,conclusion,displayTitle | \
            jq -r '.[] | select(.conclusion == "failure") | "\(.databaseId)|\(.name)"')
          
          # Common failure patterns
          http_403_count=0
          permission_error_count=0
          merge_conflict_count=0
          other_error_count=0
          
          if [ -n "$failed_runs" ]; then
            while IFS='|' read -r run_id run_name; do
              # Get logs would require additional API calls, so we'll track by pattern
              # For now, we'll check the display title for common errors
              display_title=$(gh run view "$run_id" --json displayTitle --jq '.displayTitle' 2>/dev/null || echo "")
              
              if echo "$display_title" | grep -qi "403\|forbidden\|not accessible"; then
                http_403_count=$((http_403_count + 1))
              elif echo "$display_title" | grep -qi "permission\|unauthorized"; then
                permission_error_count=$((permission_error_count + 1))
              elif echo "$display_title" | grep -qi "conflict\|merge"; then
                merge_conflict_count=$((merge_conflict_count + 1))
              else
                other_error_count=$((other_error_count + 1))
              fi
            done <<< "$failed_runs"
          fi
          
          echo "HTTP 403 errors: $http_403_count"
          echo "Permission errors: $permission_error_count"
          echo "Merge conflicts: $merge_conflict_count"
          echo "Other errors: $other_error_count"
          echo ""
          
          # Set outputs for remediation
          echo "http_403_count=${http_403_count}" >> $GITHUB_OUTPUT
          echo "permission_error_count=${permission_error_count}" >> $GITHUB_OUTPUT
          echo "merge_conflict_count=${merge_conflict_count}" >> $GITHUB_OUTPUT
          
          # Determine if intervention is needed
          if [ "$http_403_count" -gt 3 ] || [ "$permission_error_count" -gt 3 ]; then
            echo "needs_intervention=true" >> $GITHUB_OUTPUT
          else
            echo "needs_intervention=false" >> $GITHUB_OUTPUT
          fi

      - name: Create monitoring issue if needed
        if: steps.monitor.outputs.has_critical_failures == 'true' || steps.analyze.outputs.needs_intervention == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Creating monitoring alert issue..."
          
          # Check if there's already an open monitoring issue
          existing_issue=$(gh issue list --label "workflow-monitor" --state open --limit 1 --json number --jq '.[0].number' || echo "")
          
          if [ -n "$existing_issue" ]; then
            echo "Updating existing monitoring issue #${existing_issue}"
            
            gh issue comment "${existing_issue}" --body "## üîÑ Updated Workflow Health Check
            
            **Timestamp:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
            
            ### Current Status
            - **Total Workflow Runs:** ${{ steps.monitor.outputs.total_runs }}
            - **Failed Runs:** ${{ steps.monitor.outputs.failed_runs }}
            - **Failure Rate:** ${{ steps.monitor.outputs.failure_rate }}%
            
            ### Error Analysis
            - HTTP 403 Errors: ${{ steps.analyze.outputs.http_403_count }}
            - Permission Errors: ${{ steps.analyze.outputs.permission_error_count }}
            - Merge Conflicts: ${{ steps.analyze.outputs.merge_conflict_count }}
            
            ### Failed Critical Workflows
            ${{ steps.monitor.outputs.failed_workflows }}
            
            ---
            *Automated update from Workflow Monitor*"
          else
            echo "Creating new monitoring issue"
            
            gh issue create \
              --title "‚ö†Ô∏è Workflow Health Alert - $(date -u +%Y-%m-%d)" \
              --body "## Workflow Health Monitoring Alert
            
            The workflow monitor has detected issues that require attention.
            
            **Detection Time:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")
            
            ### Health Summary
            - **Total Workflow Runs:** ${{ steps.monitor.outputs.total_runs }}
            - **Failed Runs:** ${{ steps.monitor.outputs.failed_runs }}
            - **Failure Rate:** ${{ steps.monitor.outputs.failure_rate }}%
            
            ### Error Pattern Analysis
            - HTTP 403 Errors: ${{ steps.analyze.outputs.http_403_count }}
            - Permission Errors: ${{ steps.analyze.outputs.permission_error_count }}
            - Merge Conflicts: ${{ steps.analyze.outputs.merge_conflict_count }}
            
            ### Failed Critical Workflows
            ${{ steps.monitor.outputs.failed_workflows }}
            
            ### Recommended Actions
            
            #### If HTTP 403 or Permission Errors are high:
            1. Review workflow permissions in affected workflow files
            2. Ensure workflows that trigger other workflows have \`actions: write\` permission
            3. Consider using PR-based approach instead of direct commits
            4. Check if workflows need \`pull-requests: write\` permission
            
            #### If Merge Conflicts are high:
            1. Check for conflicting automated PRs
            2. Ensure auto-merge workflow is processing PRs efficiently
            3. Review branch protection rules
            
            ### Monitoring
            This issue will be automatically updated with health checks every 12 hours.
            Close this issue once all problems are resolved.
            
            ---
            *This issue was automatically created by the Workflow Monitor workflow.*" \
              --label "workflow-monitor,automated"
          fi

      - name: Generate health report
        run: |
          echo "================================================================"
          echo "Workflow Health Report"
          echo "================================================================"
          echo ""
          echo "Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
          echo ""
          echo "Summary:"
          echo "  Total Runs: ${{ steps.monitor.outputs.total_runs }}"
          echo "  Failed: ${{ steps.monitor.outputs.failed_runs }}"
          echo "  Failure Rate: ${{ steps.monitor.outputs.failure_rate }}%"
          echo ""
          echo "Error Patterns:"
          echo "  HTTP 403: ${{ steps.analyze.outputs.http_403_count }}"
          echo "  Permission: ${{ steps.analyze.outputs.permission_error_count }}"
          echo "  Merge Conflicts: ${{ steps.analyze.outputs.merge_conflict_count }}"
          echo ""
          
          if [ "${{ steps.monitor.outputs.has_critical_failures }}" = "true" ]; then
            echo "Status: ‚ö†Ô∏è  ATTENTION NEEDED"
            echo "Critical workflows have failures"
          elif [ "${{ steps.analyze.outputs.needs_intervention }}" = "true" ]; then
            echo "Status: ‚ö†Ô∏è  INTERVENTION RECOMMENDED"
            echo "High error rate detected"
          else
            echo "Status: ‚úÖ HEALTHY"
            echo "All workflows operating normally"
          fi
          echo ""
          echo "================================================================"
