name: Agent Evaluator

on:
  schedule:
    # Run daily at midnight UTC
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      force_evaluation:
        description: 'Force evaluation even if already run today'
        required: false
        type: boolean
        default: false

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  evaluate-agents:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Configure git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Ensure agent system labels exist
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üè∑Ô∏è Checking agent system labels..."
          
          # Function to create label if it doesn't exist
          create_label_if_missing() {
            local name="$1"
            local color="$2"
            local description="$3"
            
            if gh label list --repo ${{ github.repository }} | grep -q "^${name}"; then
              echo "‚úì Label '$name' already exists"
            else
              gh label create "$name" --color "$color" --description "$description" --repo ${{ github.repository }} 2>/dev/null || echo "‚ö†Ô∏è Could not create label '$name'"
            fi
          }
          
          # Create evaluation-specific labels
          create_label_if_missing "agent-system" "7057ff" "Agent ecosystem activity"
          create_label_if_missing "evaluation" "e4e669" "Agent evaluations"
          create_label_if_missing "automated" "ededed" "Auto-generated content"
          create_label_if_missing "copilot" "8b5cf6" "Copilot-related tasks"

      - name: Evaluate all agents
        id: evaluate
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import subprocess
          from datetime import datetime, timedelta
          
          REGISTRY_FILE = ".github/agent-system/registry.json"
          
          # Load registry
          with open(REGISTRY_FILE, 'r') as f:
              registry = json.load(f)
          
          active_agents = [a for a in registry.get('agents', []) if a.get('status') == 'active']
          
          if not active_agents:
              print("No active agents to evaluate")
              exit(0)
          
          print(f"üìä Evaluating {len(active_agents)} active agents...")
          
          promoted = []
          eliminated = []
          maintained = []
          
          # Import the real metrics collector
          import sys
          import importlib.util
          sys.path.insert(0, 'tools')
          try:
              spec = importlib.util.spec_from_file_location(
                  "agent_metrics_collector",
                  "tools/agent-metrics-collector.py"
              )
              metrics_module = importlib.util.module_from_spec(spec)
              spec.loader.exec_module(metrics_module)
              MetricsCollector = metrics_module.MetricsCollector
              collector = MetricsCollector()
              use_real_metrics = True
              print("‚úÖ Using real GitHub metrics collector")
          except Exception as e:
              print(f"‚ö†Ô∏è  Warning: Could not load metrics collector, using fallback: {e}")
              use_real_metrics = False
          
          for agent in active_agents:
              agent_id = agent['id']
              agent_name = agent['name']
              
              if use_real_metrics:
                  # Use real GitHub activity metrics
                  try:
                      metrics = collector.collect_metrics(agent_id, since_days=7)
                      overall_score = metrics.scores.overall
                      
                      # Update all metrics from real data
                      agent['metrics']['issues_resolved'] = metrics.activity.issues_resolved
                      agent['metrics']['prs_merged'] = metrics.activity.prs_merged
                      agent['metrics']['reviews_given'] = metrics.activity.reviews_given
                      agent['metrics']['code_quality_score'] = metrics.scores.code_quality
                      agent['metrics']['overall_score'] = overall_score
                      
                      print(f"\n{agent_name}: {overall_score:.2%} (real metrics)")
                  except Exception as e:
                      print(f"‚ö†Ô∏è  Error collecting metrics for {agent_id}, using fallback: {e}")
                      # Fallback to time-based scoring if metrics collection fails
                      spawned = datetime.fromisoformat(agent['spawned_at'].replace('Z', '+00:00'))
                      age_hours = (datetime.utcnow().replace(tzinfo=spawned.tzinfo) - spawned).total_seconds() / 3600
                      overall_score = min(0.5, age_hours / 48.0)  # Conservative scoring for new agents
                      agent['metrics']['overall_score'] = overall_score
                      print(f"\n{agent_name}: {overall_score:.2%} (fallback)")
              else:
                  # Fallback: Use time-based scoring for new agents
                  spawned = datetime.fromisoformat(agent['spawned_at'].replace('Z', '+00:00'))
                  age_hours = (datetime.utcnow().replace(tzinfo=spawned.tzinfo) - spawned).total_seconds() / 3600
                  overall_score = min(0.5, age_hours / 48.0)  # Conservative scoring
                  agent['metrics']['overall_score'] = overall_score
                  print(f"\n{agent_name}: {overall_score:.2%} (fallback)")
              
              elimination_threshold = registry['config']['elimination_threshold']
              promotion_threshold = registry['config']['promotion_threshold']
              
              print(f"\n{agent_name}: {overall_score:.2%}")
              
              # Determine fate
              if overall_score >= promotion_threshold:
                  agent['status'] = 'hall_of_fame'
                  agent['promoted_at'] = datetime.utcnow().isoformat() + 'Z'
                  registry['hall_of_fame'].append(agent)
                  promoted.append(agent)
                  print(f"  üèÜ PROMOTED to Hall of Fame!")
              elif overall_score < elimination_threshold:
                  agent['status'] = 'eliminated'
                  agent['eliminated_at'] = datetime.utcnow().isoformat() + 'Z'
                  agent['elimination_reason'] = f"Score {overall_score:.2%} below threshold {elimination_threshold:.2%}"
                  eliminated.append(agent)
                  print(f"  ‚ùå ELIMINATED (score too low)")
              else:
                  maintained.append(agent)
                  print(f"  ‚úÖ Maintained (active)")
          
          # Update registry
          # Remove promoted/eliminated from active list
          registry['agents'] = [a for a in registry['agents'] if a['status'] == 'active']
          registry['last_evaluation'] = datetime.utcnow().isoformat() + 'Z'
          
          # Update system lead (highest scoring Hall of Fame member)
          if registry['hall_of_fame']:
              top_agent = max(registry['hall_of_fame'], key=lambda a: a['metrics']['overall_score'])
              registry['system_lead'] = top_agent['id']
              print(f"\nüëë System Lead: {top_agent['name']}")
          
          with open(REGISTRY_FILE, 'w') as f:
              json.dump(registry, f, indent=2)
          
          # Output results
          print(f"\nüìä Evaluation Summary:")
          print(f"  üèÜ Promoted: {len(promoted)}")
          print(f"  ‚ùå Eliminated: {len(eliminated)}")
          print(f"  ‚úÖ Maintained: {len(maintained)}")
          
          # Save results for next steps
          with open('/tmp/evaluation_results.json', 'w') as f:
              json.dump({
                  'promoted': [{'id': a['id'], 'name': a['name'], 'score': a['metrics']['overall_score']} for a in promoted],
                  'eliminated': [{'id': a['id'], 'name': a['name'], 'score': a['metrics']['overall_score']} for a in eliminated],
                  'maintained': [{'id': a['id'], 'name': a['name'], 'score': a['metrics']['overall_score']} for a in maintained]
              }, f, indent=2)
          
          PYTHON_SCRIPT
          
          # Check if there are results to process
          if [ -f "/tmp/evaluation_results.json" ]; then
            echo "has_results=true" >> $GITHUB_OUTPUT
          else
            echo "has_results=false" >> $GITHUB_OUTPUT
          fi

      - name: Update agent profiles
        if: steps.evaluate.outputs.has_results == 'true'
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          
          # Update profiles for eliminated agents
          for agent in results.get('eliminated', []):
              profile_path = f".github/agent-system/profiles/{agent['id']}.md"
              if os.path.exists(profile_path):
                  with open(profile_path, 'r') as f:
                      content = f.read()
                  
                  # Update status
                  content = content.replace('**Status**: üü¢ Active', f"**Status**: ‚ùå Eliminated (Score: {agent['score']:.2%})")
                  
                  with open(profile_path, 'w') as f:
                      f.write(content)
          
          # Update profiles for promoted agents
          for agent in results.get('promoted', []):
              profile_path = f".github/agent-system/profiles/{agent['id']}.md"
              if os.path.exists(profile_path):
                  with open(profile_path, 'r') as f:
                      content = f.read()
                  
                  # Update status
                  content = content.replace('**Status**: üü¢ Active', f"**Status**: üèÜ Hall of Fame (Score: {agent['score']:.2%})")
                  
                  with open(profile_path, 'w') as f:
                      f.write(content)
          
          print("‚úÖ Agent profiles updated")
          PYTHON_SCRIPT

      - name: Archive eliminated agents
        if: steps.evaluate.outputs.has_results == 'true'
        run: |
          mkdir -p .github/agent-system/archive
          mkdir -p .github/agent-system/archive/definitions
          
          python3 << 'PYTHON_SCRIPT'
          import json
          import shutil
          import os
          from pathlib import Path
          
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          
          with open('.github/agent-system/registry.json', 'r') as f:
              registry = json.load(f)
          
          for agent in results.get('eliminated', []):
              agent_id = agent['id']
              
              # Archive profile
              profile_path = f".github/agent-system/profiles/{agent_id}.md"
              archive_path = f".github/agent-system/archive/{agent_id}.md"
              
              if os.path.exists(profile_path):
                  shutil.move(profile_path, archive_path)
                  print(f"üì¶ Archived profile for {agent['name']}")
              
              # Find and note the agent definition (but don't remove it - keep for future spawns)
              # Get specialization from registry
              full_agent = next((a for a in registry.get('agents', []) if a.get('id') == agent_id), None)
              if not full_agent:
                  # Check eliminated list in registry for historical data
                  continue
              
              specialization = full_agent.get('specialization', 'unknown')
              agent_def_path = Path(f".github/agents/{specialization}.md")
              
              if agent_def_path.exists():
                  print(f"  ‚ÑπÔ∏è  Agent definition {specialization}.md remains for future spawns")
          
          PYTHON_SCRIPT

      - name: Commit changes
        if: steps.evaluate.outputs.has_results == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          BRANCH_NAME="agent-evaluation/$(date +%Y%m%d-%H%M%S)"
          git checkout -b "$BRANCH_NAME"
          
          git add .github/agent-system/
          git commit -m "üîÑ Daily agent evaluation and governance"
          git push origin "$BRANCH_NAME"
          
          # Read results
          PROMOTED_COUNT=$(python3 -c "
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          print(len(results.get('promoted', [])))
          ")
          
          ELIMINATED_COUNT=$(python3 -c "
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          print(len(results.get('eliminated', [])))
          ")
          
          MAINTAINED_COUNT=$(python3 -c "
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          print(len(results.get('maintained', [])))
          ")
          
          # Build PR body
          PR_BODY="## üèõÔ∏è Daily Agent Evaluation Results

          The agent ecosystem has been evaluated based on performance metrics.

          ### Summary

          - üèÜ **Promoted to Hall of Fame**: $PROMOTED_COUNT agents
          - ‚ùå **Eliminated**: $ELIMINATED_COUNT agents  
          - ‚úÖ **Maintained Active Status**: $MAINTAINED_COUNT agents

          ### Details
          "
          
          # Add promoted agents
          if [ "$PROMOTED_COUNT" -gt 0 ]; then
            PR_BODY="$PR_BODY

          #### üèÜ Promoted to Hall of Fame
          "
            python3 << 'PYTHON_SCRIPT'
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          for agent in results.get('promoted', []):
              print(f"- **{agent['name']}** - Score: {agent['score']:.2%}")
          PYTHON_SCRIPT
          fi
          
          # Add eliminated agents
          if [ "$ELIMINATED_COUNT" -gt 0 ]; then
            PR_BODY="$PR_BODY

          #### ‚ùå Eliminated
          "
            python3 << 'PYTHON_SCRIPT'
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          for agent in results.get('eliminated', []):
              print(f"- **{agent['name']}** - Score: {agent['score']:.2%} (below threshold)")
          PYTHON_SCRIPT
          fi
          
          PR_BODY="$PR_BODY

          ### Changes

          - Updated agent registry
          - Modified agent profiles  
          - Archived eliminated agents
          - Updated system lead if applicable

          ---
          *ü§ñ Automated agent evaluation system - Survival of the fittest in action!*"
          
          gh pr create \
            --title "üèõÔ∏è Daily Agent Evaluation - $(date +%Y-%m-%d)" \
            --body "$PR_BODY" \
            --label "agent-system,evaluation,automated,copilot" \
            --base main \
            --head "$BRANCH_NAME"
          
          echo "‚úÖ Evaluation PR created"

      - name: Create evaluation report issue
        if: steps.evaluate.outputs.has_results == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import subprocess
          from datetime import datetime
          
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          
          with open('.github/agent-system/registry.json', 'r') as f:
              registry = json.load(f)
          
          title = f"üèõÔ∏è Agent Evaluation Report - {datetime.utcnow().strftime('%Y-%m-%d')}"
          
          body = f"""## üìä Daily Agent Evaluation Report

          **Date**: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

          ### Results Summary

          - üèÜ **Promoted**: {len(results.get('promoted', []))} agents
          - ‚ùå **Eliminated**: {len(results.get('eliminated', []))} agents
          - ‚úÖ **Maintained**: {len(results.get('maintained', []))} agents
          - üìä **Total Active**: {len([a for a in registry['agents'] if a['status'] == 'active'])} agents

          ### Hall of Fame

          """
          
          if registry.get('hall_of_fame'):
              body += f"{len(registry['hall_of_fame'])} agents have earned their place:\n\n"
              for hof_agent in sorted(registry['hall_of_fame'], key=lambda a: a['metrics']['overall_score'], reverse=True):
                  score = hof_agent['metrics']['overall_score']
                  is_lead = hof_agent['id'] == registry.get('system_lead')
                  crown = "üëë " if is_lead else ""
                  body += f"- {crown}**{hof_agent['name']}** - {score:.2%}\n"
          else:
              body += "*No agents in Hall of Fame yet*\n"
          
          body += "\n### System Lead\n\n"
          
          if registry.get('system_lead'):
              lead = next((a for a in registry['hall_of_fame'] if a['id'] == registry['system_lead']), None)
              if lead:
                  body += f"üëë **{lead['name']}** is currently governing the agent ecosystem.\n"
          else:
              body += "*No system lead elected yet*\n"
          
          body += """
          ### Performance Metrics

          Agents are evaluated on:
          - **Code Quality** (30%): Linting, best practices, maintainability
          - **Issue Resolution** (25%): Issues completed, time to resolution
          - **PR Success** (25%): PRs merged, review feedback
          - **Peer Review** (20%): Reviews provided, quality of feedback

          ### Next Steps

          - New agents will continue spawning every 3 hours
          - Next evaluation in 24 hours
          - Community feedback influences agent scores

          ---
          *ü§ñ Automated evaluation - May the best agents thrive!*
          """
          
          # Create issue using gh CLI
          result = subprocess.run(
              ['gh', 'issue', 'create', '--title', title, '--body', body, '--label', 'agent-system,evaluation'],
              capture_output=True,
              text=True
          )
          
          if result.returncode == 0:
              print("‚úÖ Evaluation report issue created")
          else:
              print(f"‚ö†Ô∏è Failed to create issue: {result.stderr}")
          
          PYTHON_SCRIPT

      - name: Summary
        run: |
          echo "üèõÔ∏è Agent Evaluation Complete!"
          echo ""
          if [ -f "/tmp/evaluation_results.json" ]; then
            python3 << 'PYTHON_SCRIPT'
          import json
          with open('/tmp/evaluation_results.json', 'r') as f:
              results = json.load(f)
          print(f"Promoted: {len(results.get('promoted', []))}")
          print(f"Eliminated: {len(results.get('eliminated', []))}")
          print(f"Maintained: {len(results.get('maintained', []))}")
          PYTHON_SCRIPT
          else
            echo "No agents to evaluate"
          fi
