name: "AI Pattern: Repetition Detector"

on:
  pull_request:
    types: [opened, synchronize]
    # Note: No 'paths' filters - we want to analyze ALL PRs for repetition patterns.
    # The tools used (diversity-dashboard.py, repetition-detector.py, etc.) are
    # dependencies, not trigger conditions. We need to run on every PR to detect
    # repetitive patterns across all code changes.
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      days:
        description: 'Days to analyze (default: 30)'
        required: false
        default: '30'
      threshold:
        description: 'Uniqueness threshold (default: 30)'
        required: false
        default: '30'

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  detect-repetition:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Get full history for comprehensive analysis

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Configure Git
        run: |
          git config --global --add safe.directory $GITHUB_WORKSPACE

      - name: Run Repetition Detector
        id: detect
        run: |
          days="${{ inputs.days }}"
          if [ -z "${days}" ]; then
            days="30"
          fi
          
          echo "Analyzing contributions from the last ${days} days..."
          
          # Create history directory if it doesn't exist
          mkdir -p analysis/repetition-history
          
          # Generate timestamp for historical snapshot
          TIMESTAMP=$(date -u +%Y-%m-%d-%H-%M-%S)
          
          # Run detector and save to both current and historical locations
          # Capture exit code immediately
          python3 tools/repetition-detector.py \
            -d . \
            --since-days ${days} \
            -o analysis/repetition-report.json
          
          DETECTOR_EXIT_CODE=$?
          
          # Save timestamped snapshot for trend analysis
          if [ -f analysis/repetition-report.json ]; then
            cp analysis/repetition-report.json "analysis/repetition-history/${TIMESTAMP}.json"
            
            # Update latest symlink
            cd analysis/repetition-history
            ln -sf "${TIMESTAMP}.json" latest.json
            cd ../..
          fi
          
          # Check if the script failed to run
          if [ $DETECTOR_EXIT_CODE -ne 0 ]; then
            echo "‚ö†Ô∏è  Repetition detector failed to run"
            echo "repetition_detected=false" >> $GITHUB_OUTPUT
          else
            # Script ran successfully - check if repetition flags exist in output
            if [ -f analysis/repetition-report.json ]; then
              FLAGS_COUNT=$(python3 -c "import json; print(len(json.load(open('analysis/repetition-report.json')).get('repetition_flags', [])))" 2>/dev/null || echo "0")
              if [ "$FLAGS_COUNT" -gt 0 ]; then
                echo "repetition_detected=true" >> $GITHUB_OUTPUT
                echo "‚úÖ Detected ${FLAGS_COUNT} repetition flags"
              else
                echo "repetition_detected=false" >> $GITHUB_OUTPUT
                echo "‚úÖ No repetition detected"
              fi
            else
              echo "repetition_detected=false" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è  Report file not found"
            fi
          fi
          
          echo "days=${days}" >> $GITHUB_OUTPUT
          echo "timestamp=${TIMESTAMP}" >> $GITHUB_OUTPUT

      - name: Run Uniqueness Scorer
        id: score
        continue-on-error: true
        run: |
          threshold="${{ inputs.threshold }}"
          if [ -z "${threshold}" ]; then
            threshold="30"
          fi
          
          echo "Calculating uniqueness scores (threshold: ${threshold})..."
          
          # Run scorer and capture exit code
          python3 tools/uniqueness-scorer.py \
            -d . \
            --threshold ${threshold} \
            --days 90 \
            -o analysis/uniqueness-scores.json
          
          EXIT_CODE=$?
          
          # Exit code 1 means agents are below threshold (expected behavior)
          # This is informational, not a failure
          if [ $EXIT_CODE -ne 0 ]; then
            echo "below_threshold=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  Some agents are below uniqueness threshold (this is informational)"
          else
            echo "below_threshold=false" >> $GITHUB_OUTPUT
            echo "‚úÖ All agents meet uniqueness threshold"
          fi
          
          echo "threshold=${threshold}" >> $GITHUB_OUTPUT
          
          # Always succeed - the exit code is informational only
          exit 0

      - name: Generate Diversity Suggestions
        id: suggest
        if: steps.detect.outputs.repetition_detected == 'true' || steps.score.outputs.below_threshold == 'true'
        run: |
          echo "Generating diversity suggestions..."
          
          python3 tools/diversity-suggester.py \
            --repetition-report analysis/repetition-report.json \
            -d . \
            -o analysis/diversity-suggestions.md
          
          echo "suggestions_generated=true" >> $GITHUB_OUTPUT

      - name: Analyze Diversity Trends
        id: trends
        run: |
          echo "Analyzing diversity trends from historical data..."
          
          python3 tools/trend-analyzer.py \
            -d . \
            --days 90 \
            -o analysis/diversity-trends.json
          
          echo "trends_analyzed=true" >> $GITHUB_OUTPUT

      - name: Generate Diversity Dashboard
        id: dashboard
        run: |
          echo "Generating diversity dashboard..."
          
          python3 tools/diversity-dashboard.py \
            -d . \
            -o docs/diversity-dashboard.md
          
          echo "dashboard_generated=true" >> $GITHUB_OUTPUT

      - name: Extract Summary Statistics
        id: stats
        run: |
          # Extract key metrics from reports
          if [ -f analysis/repetition-report.json ]; then
            total_agents=$(python3 -c "import json; d=json.load(open('analysis/repetition-report.json')); print(d['summary']['total_agents'])" 2>/dev/null || echo "0")
            total_flags=$(python3 -c "import json; d=json.load(open('analysis/repetition-report.json')); print(len(d.get('repetition_flags', [])))" 2>/dev/null || echo "0")
            echo "total_agents=${total_agents}" >> $GITHUB_OUTPUT
            echo "total_flags=${total_flags}" >> $GITHUB_OUTPUT
          else
            echo "total_agents=0" >> $GITHUB_OUTPUT
            echo "total_flags=0" >> $GITHUB_OUTPUT
          fi
          
          if [ -f analysis/uniqueness-scores.json ]; then
            avg_score=$(python3 -c "import json; d=json.load(open('analysis/uniqueness-scores.json')); print(d.get('summary', {}).get('average_score', 0))" 2>/dev/null || echo "0")
            flagged_count=$(python3 -c "import json; d=json.load(open('analysis/uniqueness-scores.json')); print(len(d.get('flagged_agents', [])))" 2>/dev/null || echo "0")
            echo "avg_score=${avg_score}" >> $GITHUB_OUTPUT
            echo "flagged_count=${flagged_count}" >> $GITHUB_OUTPUT
          else
            echo "avg_score=0" >> $GITHUB_OUTPUT
            echo "flagged_count=0" >> $GITHUB_OUTPUT
          fi

      - name: Post PR Comment
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          pr_number="${{ github.event.pull_request.number }}"
          
          # Create comment file
          cat > /tmp/pr_comment.md << 'COMMENT_EOF'
          ## üé® AI Pattern Repetition Analysis
          
          **Analysis Period:** Last ${{ steps.detect.outputs.days }} days
          **Uniqueness Threshold:** ${{ steps.score.outputs.threshold }}
          
          ### Results:
          - **Total Agents Analyzed:** ${{ steps.stats.outputs.total_agents }}
          - **Average Uniqueness Score:** ${{ steps.stats.outputs.avg_score }}
          - **Repetition Flags:** ${{ steps.stats.outputs.total_flags }}
          - **Agents Below Threshold:** ${{ steps.stats.outputs.flagged_count }}
          COMMENT_EOF
          
          if [ "${{ steps.suggest.outputs.suggestions_generated }}" = "true" ]; then
            cat >> /tmp/pr_comment.md << 'COMMENT_EOF'
          
          ### ‚ö†Ô∏è Action Required
          
          Repetition patterns detected! Check the diversity suggestions for concrete recommendations.
          
          üìÑ See `analysis/diversity-suggestions.md` for detailed suggestions.
          COMMENT_EOF
          else
            cat >> /tmp/pr_comment.md << 'COMMENT_EOF'
          
          ### ‚úÖ All Clear
          
          No significant repetition detected. All agents show healthy diversity!
          COMMENT_EOF
          fi
          
          cat >> /tmp/pr_comment.md << 'COMMENT_EOF'
          
          ---
          *Analysis reports available in `analysis/` directory*
          COMMENT_EOF
          
          # Post comment
          gh pr comment ${pr_number} --body-file /tmp/pr_comment.md || true

      - name: Create Issue for Significant Repetition
        if: steps.stats.outputs.total_flags != '0' && steps.stats.outputs.total_flags != ''
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          total_flags="${{ steps.stats.outputs.total_flags }}"
          flagged_count="${{ steps.stats.outputs.flagged_count }}"
          
          # Only create issue if:
          # 1. There are actual agents flagged (not just repetition patterns)
          # 2. More than 2 flags OR more than 1 agent flagged below threshold
          # This prevents false positives from system bot data
          if [ "${flagged_count}" -gt 0 ] && ([ "${total_flags}" -gt 2 ] || [ "${flagged_count}" -gt 1 ]); then
            # Extract flagged agent details for better reporting
            flagged_agents=$(python3 -c '
          import json
          with open("analysis/uniqueness-scores.json") as f:
              data = json.load(f)
              flagged = data.get("flagged_agents", [])
              if flagged:
                  for agent in flagged:
                      print(f"- **{agent[\"agent_id\"]}**: Score {agent[\"score\"]} - {agent[\"reason\"]}")
              else:
                  print("- None (all agents above threshold)")
          ' 2>/dev/null) || flagged_agents="- Error extracting agent details"
            
            cat > /tmp/issue_body.md << 'ISSUE_EOF'
          ## AI Agent Repetition Detected
          
          The pattern repetition detection system has identified concerning patterns in AI agent contributions.
          
          ### Summary:
          - **Repetition Flags:** TOTAL_FLAGS_PLACEHOLDER
          - **Agents Flagged:** FLAGGED_COUNT_PLACEHOLDER
          - **Average Uniqueness Score:** AVG_SCORE_PLACEHOLDER
          - **Analysis Period:** Last DAYS_PLACEHOLDER days
          
          ### Flagged Agents:
          FLAGGED_AGENTS_LIST
          
          ### Impact:
          Repetitive patterns may indicate:
          - Agents falling into habitual approaches
          - Lack of diversity in problem-solving strategies
          - Potential for missed innovative solutions
          - Risk of creating technical debt
          
          ### Action Items:
          1. Review `analysis/diversity-suggestions.md` for specific recommendations
          2. Examine flagged agents' recent contributions
          3. Consider updating agent prompts to encourage diversity
          4. Share successful diverse patterns with the team
          
          ### Reports:
          - üìä Repetition Report: `analysis/repetition-report.json`
          - üéØ Uniqueness Scores: `analysis/uniqueness-scores.json`
          - üí° Suggestions: `analysis/diversity-suggestions.md`
          
          ---
          *Automatically generated by the AI Pattern Repetition Detector*
          ISSUE_EOF
            
            # Replace placeholders
            sed -i "s/TOTAL_FLAGS_PLACEHOLDER/${total_flags}/g" /tmp/issue_body.md
            sed -i "s/FLAGGED_COUNT_PLACEHOLDER/${{ steps.stats.outputs.flagged_count }}/g" /tmp/issue_body.md
            sed -i "s/AVG_SCORE_PLACEHOLDER/${{ steps.stats.outputs.avg_score }}/g" /tmp/issue_body.md
            sed -i "s/DAYS_PLACEHOLDER/${{ steps.detect.outputs.days }}/g" /tmp/issue_body.md
            
            # Insert flagged agents list (properly escaped for sed)
            echo "${flagged_agents}" > /tmp/flagged_agents.txt
            sed -i "/FLAGGED_AGENTS_LIST/r /tmp/flagged_agents.txt" /tmp/issue_body.md
            sed -i "/FLAGGED_AGENTS_LIST/d" /tmp/issue_body.md
            
            # Create issue with fallback if labels don't exist
            gh issue create \
              --title "‚ö†Ô∏è AI Agent Repetition Alert: ${total_flags} patterns detected" \
              --body-file /tmp/issue_body.md \
              --label "automated" || {
                echo "‚ö†Ô∏è Issue creation with labels failed, retrying without labels..."
                gh issue create \
                  --title "‚ö†Ô∏è AI Agent Repetition Alert: ${total_flags} patterns detected" \
                  --body-file /tmp/issue_body.md
              }
          fi

      - name: Commit Analysis Results
        if: github.event_name != 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Add analysis files (including historical snapshots)
          git add analysis/repetition-report.json analysis/uniqueness-scores.json analysis/pattern-diversity.json || true
          git add analysis/repetition-history/ || true
          git add analysis/diversity-trends.json || true
          
          if [ -f analysis/diversity-suggestions.md ]; then
            git add analysis/diversity-suggestions.md
          fi
          
          # Add dashboard to docs
          if [ -f docs/diversity-dashboard.md ]; then
            git add docs/diversity-dashboard.md
          fi
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Create a new branch for the PR with unique name using run ID
            TIMESTAMP=$(date +%Y%m%d-%H%M%S)
            BRANCH_NAME="repetition-analysis/${TIMESTAMP}-${{ github.run_id }}"
            git checkout -b "$BRANCH_NAME"
            
            git commit -m "ü§ñ Update pattern repetition analysis" \
                       -m "Analyzed: ${{ steps.stats.outputs.total_agents }} agents" \
                       -m "Flags: ${{ steps.stats.outputs.total_flags }}" \
                       -m "Average score: ${{ steps.stats.outputs.avg_score }}" \
                       -m "Timestamp: ${{ steps.detect.outputs.timestamp }}" \
                       -m "Dashboard updated: ${{ steps.dashboard.outputs.dashboard_generated }}"
            
            # Push branch
            git push origin "$BRANCH_NAME"
            
            # Create PR (with fallback if labels don't exist)
            PR_DATE=$(date +%Y-%m-%d)
            gh pr create \
              --title "ü§ñ Update pattern repetition analysis - ${PR_DATE}" \
              --body "## Pattern Repetition Analysis Update"$'\n\n'"This PR updates the pattern repetition analysis results."$'\n\n'"### Analysis Results"$'\n'"- **Agents analyzed**: ${{ steps.stats.outputs.total_agents }}"$'\n'"- **Flags**: ${{ steps.stats.outputs.total_flags }}"$'\n'"- **Average score**: ${{ steps.stats.outputs.avg_score }}"$'\n\n'"---"$'\n'"*ü§ñ Automated pattern analysis workflow*" \
              --label "automated,copilot" \
              --base main \
              --head "$BRANCH_NAME" || {
                echo "‚ö†Ô∏è PR creation with labels failed, retrying without labels..."
                gh pr create \
                  --title "ü§ñ Update pattern repetition analysis - ${PR_DATE}" \
                  --body "## Pattern Repetition Analysis Update"$'\n\n'"This PR updates the pattern repetition analysis results."$'\n\n'"### Analysis Results"$'\n'"- **Agents analyzed**: ${{ steps.stats.outputs.total_agents }}"$'\n'"- **Flags**: ${{ steps.stats.outputs.total_flags }}"$'\n'"- **Average score**: ${{ steps.stats.outputs.avg_score }}"$'\n\n'"---"$'\n'"*ü§ñ Automated pattern analysis workflow (labels unavailable)*" \
                  --base main \
                  --head "$BRANCH_NAME"
              }
            
            echo "‚úÖ PR created for analysis update"
          fi

      - name: Upload Analysis Reports
        uses: actions/upload-artifact@v4
        with:
          name: repetition-analysis-reports
          path: |
            analysis/repetition-report.json
            analysis/uniqueness-scores.json
            analysis/diversity-suggestions.md
            analysis/diversity-trends.json
            analysis/repetition-history/*.json
            docs/diversity-dashboard.md
          retention-days: 30

      - name: Log Activity
        run: |
          echo "=========================================="
          echo "Pattern Repetition Analysis Complete"
          echo "=========================================="
          echo "Timestamp: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          echo "Agents analyzed: ${{ steps.stats.outputs.total_agents }}"
          echo "Repetition flags: ${{ steps.stats.outputs.total_flags }}"
          echo "Average uniqueness score: ${{ steps.stats.outputs.avg_score }}"
          echo "Agents below threshold: ${{ steps.stats.outputs.flagged_count }}"
          echo "=========================================="
