#!/usr/bin/env python3
"""
Integrated Code Archaeology and Design Decision Documentation

This tool combines the code archaeologist and design decision documenter
to provide a comprehensive view of code history and decision making.

Performance-optimized by @accelerate-specialist
"""

import os
import sys
import json
import argparse
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional

# Import both tools
import importlib.util

# Import code archaeologist
spec = importlib.util.spec_from_file_location(
    "code_archaeologist",
    os.path.join(os.path.dirname(__file__), "code-archaeologist.py")
)
code_archaeologist_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(code_archaeologist_module)
CodeArchaeologist = code_archaeologist_module.CodeArchaeologist

# Import design decision documenter
spec = importlib.util.spec_from_file_location(
    "design_decision_documenter",
    os.path.join(os.path.dirname(__file__), "design-decision-documenter.py")
)
design_decision_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(design_decision_module)
DesignDecisionDocumenter = design_decision_module.DesignDecisionDocumenter


class IntegratedArchaeologySystem:
    """
    Integrated system that combines archaeology and design decisions
    
    Provides:
    - Historical context from archaeology
    - Structured design decisions
    - Cross-referenced insights
    - Unified reporting
    """
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = repo_path
        self.archaeologist = CodeArchaeologist(repo_path=repo_path)
        self.documenter = DesignDecisionDocumenter(repo_path=repo_path)
    
    def analyze_repository(self, max_commits: int = 500, since: Optional[str] = None):
        """
        Run comprehensive analysis combining both tools
        
        Performance: Analyzes commits once, extracts both types of information
        """
        print("üèõÔ∏è Running integrated code archaeology and design decision analysis...")
        print(f"üìä Max commits: {max_commits}")
        if since:
            print(f"üìÖ Since: {since}")
        
        # Extract design decisions (more specific)
        print("\nüèóÔ∏è Phase 1: Extracting design decisions...")
        decisions = self.documenter.extract_decisions(max_commits=max_commits, since=since)
        
        for decision in decisions:
            self.documenter.add_decision(decision)
        
        print(f"‚úì Found {len(decisions)} design decisions")
        
        # Run archaeology analysis (broader context)
        print("\nüèõÔ∏è Phase 2: Running code archaeology...")
        archaeology_report = self.archaeologist.analyze_repository(max_commits=max_commits)
        
        # Cross-reference decisions with archaeology data
        print("\nüîó Phase 3: Cross-referencing data...")
        cross_references = self._cross_reference_data()
        
        print(f"‚úì Found {len(cross_references)} cross-references")
        
        return {
            "decisions": decisions,
            "archaeology": archaeology_report,
            "cross_references": cross_references
        }
    
    def _cross_reference_data(self) -> List[Dict]:
        """
        Cross-reference design decisions with archaeology data
        
        Links:
        - Decisions to architectural changes
        - Decisions to technical debt
        - Decisions to evolution patterns
        """
        cross_refs = []
        
        archaeology_data = self.archaeologist.archaeology_data
        decisions_data = self.documenter._load_decisions()
        
        # Get all decisions
        decisions = decisions_data.get("decisions", [])
        
        # Get archaeology data
        arch_decisions = archaeology_data.get("architectural_decisions", [])
        tech_debt = archaeology_data.get("technical_debt", [])
        
        # Match decisions to architectural changes
        for decision in decisions:
            decision_commit = decision.get("commit", "")
            
            # Find matching archaeology entries
            matching_arch = [
                ad for ad in arch_decisions
                if ad.get("commit", "").startswith(decision_commit[:7])
            ]
            
            matching_debt = [
                td for td in tech_debt
                if td.get("commit", "").startswith(decision_commit[:7])
            ]
            
            if matching_arch or matching_debt:
                cross_refs.append({
                    "decision_id": decision.get("id"),
                    "decision_title": decision.get("title"),
                    "archaeology_entries": matching_arch,
                    "tech_debt_entries": matching_debt
                })
        
        return cross_refs
    
    def generate_integrated_report(self) -> str:
        """Generate comprehensive report combining both systems"""
        report = []
        
        # Header
        report.append("# üèõÔ∏è Integrated Code Archaeology & Design Decisions Report")
        report.append(f"\n**Generated:** {datetime.now(timezone.utc).isoformat()}")
        report.append(f"**Repository:** {os.path.basename(os.path.abspath(self.repo_path))}")
        
        # Design Decisions Summary
        decisions_data = self.documenter._load_decisions()
        report.append("\n## üèóÔ∏è Design Decisions Summary")
        report.append(f"- Total decisions: {decisions_data.get('total_decisions', 0)}")
        
        stats = decisions_data.get("statistics", {})
        report.append(f"- Accepted: {stats.get('accepted', 0)}")
        report.append(f"- Rejected: {stats.get('rejected', 0)}")
        report.append(f"- Deprecated: {stats.get('deprecated', 0)}")
        
        # Archaeology Summary
        archaeology_data = self.archaeologist.archaeology_data
        report.append("\n## üèõÔ∏è Code Archaeology Summary")
        report.append(f"- Commits analyzed: {archaeology_data.get('total_commits_analyzed', 0)}")
        report.append(f"- Architectural decisions: {len(archaeology_data.get('architectural_decisions', []))}")
        report.append(f"- Technical debt items: {len(archaeology_data.get('technical_debt', []))}")
        
        # Cross-references
        cross_refs = self._cross_reference_data()
        if cross_refs:
            report.append("\n## üîó Cross-Referenced Insights")
            report.append(f"Found {len(cross_refs)} decisions with archaeological context:")
            
            for ref in cross_refs[:5]:  # Show top 5
                report.append(f"\n### {ref['decision_id']}: {ref['decision_title']}")
                
                if ref['archaeology_entries']:
                    report.append(f"- Linked to {len(ref['archaeology_entries'])} architectural changes")
                
                if ref['tech_debt_entries']:
                    report.append(f"- Associated with {len(ref['tech_debt_entries'])} tech debt items")
        
        # Recent Decisions with Context
        decisions = decisions_data.get("decisions", [])
        if decisions:
            report.append("\n## üìã Recent Design Decisions")
            
            sorted_decisions = sorted(
                decisions,
                key=lambda d: d.get("date", ""),
                reverse=True
            )[:5]
            
            for decision in sorted_decisions:
                report.append(f"\n### {decision.get('id')}: {decision.get('title')}")
                report.append(f"**Date:** {decision.get('date', 'Unknown')[:10]}")
                report.append(f"**Status:** {decision.get('status')}")
                report.append(f"**Category:** {decision.get('category')}")
                
                if decision.get("decision"):
                    report.append(f"\n{decision['decision'][:200]}...")
        
        # Performance metrics
        report.append("\n## üöÄ Performance Characteristics")
        report.append("- **Design Decision Lookups:** O(1) with hash indexing")
        report.append("- **Category Queries:** O(log n) with indexed search")
        report.append("- **Cross-references:** O(n*m) where n=decisions, m=archaeology entries")
        report.append("- **Memory:** Lazy loading with caching")
        
        return '\n'.join(report)
    
    def export_all(self, decisions_dir: str = "docs/decisions", archaeology_dir: str = "docs/archaeology"):
        """Export all documentation to markdown files"""
        print(f"\nüìÅ Exporting all documentation...")
        
        # Export design decisions
        self.documenter.export_to_markdown(decisions_dir)
        print(f"‚úì Design decisions exported to {decisions_dir}")
        
        # Export archaeology data (create markdown summaries)
        os.makedirs(archaeology_dir, exist_ok=True)
        
        archaeology_data = self.archaeologist.archaeology_data
        
        # Export architectural decisions
        self._export_archaeology_markdown(
            archaeology_data.get("architectural_decisions", []),
            os.path.join(archaeology_dir, "architectural-decisions.md"),
            "Architectural Decisions"
        )
        
        # Export technical debt
        self._export_archaeology_markdown(
            archaeology_data.get("technical_debt", []),
            os.path.join(archaeology_dir, "technical-debt.md"),
            "Technical Debt"
        )
        
        print(f"‚úì Archaeology data exported to {archaeology_dir}")
        
        # Create index
        self._create_combined_index(decisions_dir, archaeology_dir)
    
    def _export_archaeology_markdown(self, items: List[Dict], filepath: str, title: str):
        """Export archaeology items to markdown"""
        lines = []
        lines.append(f"# {title}")
        lines.append(f"\n**Total items:** {len(items)}")
        lines.append(f"**Generated:** {datetime.now(timezone.utc).isoformat()}\n")
        
        for item in items:
            lines.append(f"\n## {item.get('content', 'No content')[:100]}")
            lines.append(f"**Commit:** `{item.get('commit', 'unknown')}`")
            lines.append(f"**Date:** {item.get('timestamp', 'Unknown')}")
            lines.append(f"**Type:** {item.get('type', 'unknown')}")
        
        with open(filepath, 'w') as f:
            f.write('\n'.join(lines))
    
    def _create_combined_index(self, decisions_dir: str, archaeology_dir: str):
        """Create combined index of all documentation"""
        index_path = "docs/README.md"
        
        lines = []
        lines.append("# Code Documentation Index")
        lines.append("\nIntegrated code archaeology and design decision documentation")
        lines.append(f"\n**Generated:** {datetime.now(timezone.utc).isoformat()}")
        
        lines.append("\n## üèóÔ∏è Design Decisions")
        lines.append(f"\nStructured documentation of architectural and technical choices.")
        lines.append(f"\n[Browse Design Decisions](./{os.path.basename(decisions_dir)}/README.md)")
        
        lines.append("\n## üèõÔ∏è Code Archaeology")
        lines.append(f"\nHistorical analysis of code evolution and technical debt.")
        lines.append(f"\n- [Architectural Decisions](./{os.path.basename(archaeology_dir)}/architectural-decisions.md)")
        lines.append(f"- [Technical Debt](./{os.path.basename(archaeology_dir)}/technical-debt.md)")
        
        lines.append("\n## üîó Quick Links")
        lines.append("\n- [Design Decisions Database](../analysis/design-decisions.json)")
        lines.append("- [Archaeology Database](../analysis/archaeology.json)")
        
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        with open(index_path, 'w') as f:
            f.write('\n'.join(lines))
        
        print(f"‚úì Combined index created at {index_path}")


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description='Integrated Code Archaeology and Design Decision Documentation'
    )
    parser.add_argument(
        '-d', '--directory',
        default='.',
        help='Repository directory to analyze (default: current directory)'
    )
    parser.add_argument(
        '-n', '--max-commits',
        type=int,
        default=500,
        help='Maximum number of commits to analyze (default: 500)'
    )
    parser.add_argument(
        '--since',
        help='Only analyze commits since this date'
    )
    parser.add_argument(
        '-o', '--output',
        help='Output file for integrated report'
    )
    parser.add_argument(
        '--export',
        action='store_true',
        help='Export all documentation to markdown files'
    )
    
    args = parser.parse_args()
    
    # Initialize integrated system
    system = IntegratedArchaeologySystem(repo_path=args.directory)
    
    # Run analysis
    results = system.analyze_repository(
        max_commits=args.max_commits,
        since=args.since
    )
    
    # Generate report
    report = system.generate_integrated_report()
    
    if args.output:
        with open(args.output, 'w') as f:
            f.write(report)
        print(f"\n‚úÖ Integrated report saved to: {args.output}")
    else:
        print(f"\n{report}")
    
    # Export if requested
    if args.export:
        system.export_all()
    
    print("\n‚úÖ Analysis complete!")
    print(f"   - Design decisions: {len(results['decisions'])}")
    print(f"   - Cross-references: {len(results['cross_references'])}")


if __name__ == '__main__':
    main()
