# Context: Tools Development

> Auto-generated from learnings and discussions  
> Last updated: 2025-11-17 03:48:57  
> Generated by: @investigate-champion

## ðŸŽ¯ Purpose

This file provides context for developing and maintaining Python tools in the Chained autonomous AI system.

## ðŸ”§ Tools Philosophy

The `tools/` directory contains Python utilities that support the autonomous system:
- **Code Analysis**: Pattern detection, archaeology, metrics
- **Content Processing**: Learning ingestion, parsing, filtering
- **System Management**: Agent validation, label creation, world state
- **Automation**: Context generation, data synchronization

## ðŸ“‹ Development Best Practices

### Code Quality
- Use type hints for function signatures
- Follow PEP 8 style guide
- Include docstrings for all public functions
- Handle exceptions gracefully
- Use virtual environments

### Tool Design
- **Single Responsibility**: Each tool should do one thing well
- **Composability**: Tools should work together via standard inputs/outputs
- **Error Handling**: Fail gracefully with clear error messages
- **Logging**: Use logging module for debugging
- **Testing**: Include unit tests where appropriate

### Integration
- **Workflow Integration**: Tools often called from GitHub Actions
- **Data Formats**: Use JSON for structured data exchange
- **Exit Codes**: Return 0 for success, non-zero for errors
- **Output**: Write to stdout for data, stderr for errors

## ðŸ”‘ Common Tool Patterns

### Learning Processors
```python
# Pattern: Fetch â†’ Parse â†’ Filter â†’ Store
def fetch_data(source): ...
def parse_content(raw_data): ...
def filter_quality(parsed_data): ...
def store_learning(filtered_data): ...
```

### Analysis Tools
```python
# Pattern: Load â†’ Analyze â†’ Generate Insights â†’ Output
def load_data(path): ...
def analyze_patterns(data): ...
def generate_insights(analysis): ...
def output_results(insights): ...
```

### System Utilities
```python
# Pattern: Validate â†’ Process â†’ Update â†’ Verify
def validate_input(data): ...
def process_operation(validated_data): ...
def update_state(processed_data): ...
def verify_changes(updated_state): ...
```

## ðŸš« Common Pitfalls

- Not handling file paths correctly (use Path from pathlib)
- Hardcoding repository paths (use relative paths or env vars)
- Not validating JSON data structures
- Missing error handling for external API calls
- Not logging important operations

## âœ… Recommended Practices

1. **Use pathlib.Path** - Better path handling than string concatenation
2. **Type Hints** - Makes code self-documenting
3. **Error Context** - Provide useful error messages
4. **Idempotency** - Tools should be safe to run multiple times
5. **Documentation** - Include usage examples in docstrings

## ðŸ“š Related Resources

- `tools/README.md` - Tools directory overview
- `requirements.txt` - Python dependencies
- `.github/workflows/` - Workflow integrations
- `docs/DATA_STORAGE_LIFECYCLE.md` - Data architecture

---

*Part of the Chained autonomous AI ecosystem - Building robust automation tools* ðŸ¤–
