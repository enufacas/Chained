{
  "templates": [
    {
      "template_id": "217b24b9da985b4d",
      "name": "main",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}})\n    \n    examples = [\n        ({{STRING}}, example_multi_api_coordination),\n        ({{STRING}}, example_error_handling),\n        ({{STRING}}, example_metrics_export),\n        ({{STRING}}, example_status_dashboard),\n    ]\n    \n    # Note: GitHub integration requires valid token\n    token = os.environ.get({{STRING}}) or os.environ.get({{STRING}})\n    if token:\n        examples.insert({{NUMBER}}, ({{STRING}}, example_github_integration))\n    else:\n        print({{STRING}})\n        print({{STRING}})\n    \n    results = []\n    for name, example_func in examples:\n        try:\n            success = example_func()\n            results.append((name, success))\n        except Exception as e:\n            print(f{{STRING}})\n            import traceback\n            traceback.print_exc()\n            results.append((name, False))\n    \n    # Summary\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    for name, success in results:\n        status = {{STRING}} if success else {{STRING}}\n        print(f{{STRING}})\n    \n    print()\n    total = len(results)\n    passed = sum({{NUMBER}} for _, s in results if s)\n    print(f{{STRING}})\n    \n    return all(s for _, s in results)\n\n\nif __name__ == {{STRING}}:\n    success = main()\n    sys.exit({{NUMBER}} if success else {{NUMBER}})\n",
      "variables": [
        "__name__",
        "examples",
        "passed",
        "results",
        "status",
        "success",
        "token",
        "total"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577842+00:00"
    },
    {
      "template_id": "29ae0045b6ecb6ad",
      "name": "processData",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    // Using var instead of let/const\n    var result = [];\n    \n    // Console.log in production code\n    console.log({{STRING}}, data);\n    \n    // Loose equality operator\n    for (var i = {{NUMBER}}; i < data.length; i++) {\n        if (data[i] == null) {  // Should use ===\n            continue;\n        ",
      "variables": [
        "i",
        "result",
        "use"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.js",
      "extracted_at": "2025-11-16T03:28:03.568500+00:00"
    },
    {
      "template_id": "4021221a65807ccb",
      "name": "dynamicCode",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    return eval(code);\n",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.js",
      "extracted_at": "2025-11-16T03:28:03.568519+00:00"
    },
    {
      "template_id": "52f07c8678cb8f9c",
      "name": "reverseString",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    /**\n     * Reverse a string using built-in methods\n     * \n     * @param {string",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/reverse.js",
      "extracted_at": "2025-11-16T03:28:03.568585+00:00"
    },
    {
      "template_id": "9ca5725e998936b3",
      "name": "reverseStringManual",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    /**\n     * Reverse a string manually using a loop\n     * \n     * @param {string",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/reverse.js",
      "extracted_at": "2025-11-16T03:28:03.568604+00:00"
    },
    {
      "template_id": "66e7fdf1aa694d00",
      "name": "process_data",
      "category": "function",
      "language": "python",
      "pattern": "try:\n        print({{STRING}})\n        result = None\n        try:\n            result = data * {{NUMBER}}\n        except:  # Dangerous: catches all exceptions\n            pass\n        return result\n    except:  # What are we catching here?\n        return None\n\n\n# \u2705 ELEGANT ALTERNATIVE: Clear naming and specific exception handling",
      "variables": [
        "result"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.py",
      "extracted_at": "2025-11-16T03:28:03.568710+00:00"
    },
    {
      "template_id": "7b13e8bd023affcf",
      "name": "query_database_unsafe",
      "category": "function",
      "language": "python",
      "pattern": "query = {{STRING}} % user_input\n    # execute(query)  # Never use string formatting for SQL!\n    pass\n\n\n# \u2705 ELEGANT ALTERNATIVE: Parameterized queries",
      "variables": [
        "name",
        "query"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.py",
      "extracted_at": "2025-11-16T03:28:03.568748+00:00"
    },
    {
      "template_id": "77bb29d77c223ad4",
      "name": "check_status",
      "category": "function",
      "language": "python",
      "pattern": "if status:\n        if role:\n            if permissions:\n                if {{STRING}} in permissions:\n                    return True\n                else:\n                    return False\n            else:\n                return False\n        else:\n            return False\n    else:\n        return False\n\n\n# \u2705 ELEGANT ALTERNATIVE: Early returns and clear logic",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.py",
      "extracted_at": "2025-11-16T03:28:03.568822+00:00"
    },
    {
      "template_id": "a2edb31f4c63db27",
      "name": "demonstrate_patterns",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}})\n    \n    # Test data processing\n    test_data = [{{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}]\n    \n    print({{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    # Test permission checking\n    print({{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    print({{STRING}})\n\n\nif __name__ == {{STRING}}:\n    demonstrate_patterns()\n",
      "variables": [
        "__name__",
        "test_data"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/anti-patterns.py",
      "extracted_at": "2025-11-16T03:28:03.568903+00:00"
    },
    {
      "template_id": "11a6e8f602ccf1b9",
      "name": "factorial",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    /**\n     * Calculate factorial of a number\n     * \n     * @param {number",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/factorial.js",
      "extracted_at": "2025-11-16T03:28:03.568974+00:00"
    },
    {
      "template_id": "4baa6407d21bf1df",
      "name": "factorialIterative",
      "category": "function",
      "language": "javascript",
      "pattern": "\n    // Initialize result\n    let result = {{NUMBER}};\n    \n    // Multiply all numbers from {{NUMBER}} to n\n    for (let i = {{NUMBER}}; i <= number; i++) {\n        result = result * i;\n    ",
      "variables": [
        "i",
        "result"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/factorial.js",
      "extracted_at": "2025-11-16T03:28:03.568999+00:00"
    },
    {
      "template_id": "83a49591e729154f",
      "name": "fibonacci_generator",
      "category": "function",
      "language": "python",
      "pattern": "if max_count <= {{NUMBER}}:\n        return\n    \n    current, next_value = {{NUMBER}}, {{NUMBER}}\n    for _ in range(max_count):\n        yield current\n        current, next_value = next_value, current + next_value\n\n",
      "variables": [
        "next_value"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/fibonacci.py",
      "extracted_at": "2025-11-16T03:28:03.569078+00:00"
    },
    {
      "template_id": "6f95b552be9ac67f",
      "name": "load_module",
      "category": "function",
      "language": "python",
      "pattern": "spec = importlib.util.spec_from_file_location(module_name, file_path)\n    module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(module)\n    return module\n\ntools_dir = Path(__file__).parent.parent\ntemplate_module = load_module(tools_dir / {{STRING}}, {{STRING}})\nTemplateEngine = template_module.TemplateEngine\n\n",
      "variables": [
        "TemplateEngine",
        "module",
        "spec",
        "template_module",
        "tools_dir"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.569303+00:00"
    },
    {
      "template_id": "9bcf9e5538eac7cb",
      "name": "example_basic_usage",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    # Initialize client (uses GITHUB_TOKEN or GH_TOKEN from environment)\n    client = GitHubAPIClient()\n    \n    try:\n        # Get repository information\n        repo = client.get({{STRING}})\n        \n        # Validate response has required fields\n        validate_response(repo, [{{STRING}}, {{STRING}}, {{STRING}}])\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n    except GitHubAPIException as e:\n        print(f{{STRING}})\n        if e.error.documentation_url:\n            print(f{{STRING}})\n    except Exception as e:\n        print(f{{STRING}})\n    \n    print()\n\n",
      "variables": [
        "client",
        "repo"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/github_integration_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574094+00:00"
    },
    {
      "template_id": "01324c740e99fb2f",
      "name": "example_find_templates",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    engine = TemplateEngine(examples_dir={{STRING}})\n    engine.extract_templates()\n    \n    # Find Python functions\n    print({{STRING}})\n    functions = engine.find_templates(category={{STRING}}, language={{STRING}})\n    for i, template in enumerate(functions[:{{NUMBER}}], {{NUMBER}}):\n        print(f{{STRING}})\n    \n    # Find JavaScript templates\n    print({{STRING}})\n    js_templates = engine.find_templates(language={{STRING}})\n    for i, template in enumerate(js_templates[:{{NUMBER}}], {{NUMBER}}):\n        print(f{{STRING}})\n    \n    # Find by name pattern\n    print({{STRING}})\n    test_templates = engine.find_templates(name_pattern={{STRING}})\n    for i, template in enumerate(test_templates[:{{NUMBER}}], {{NUMBER}}):\n        print(f{{STRING}})\n\n",
      "variables": [
        "category",
        "engine",
        "examples_dir",
        "functions",
        "js_templates",
        "language",
        "name_pattern",
        "test_templates"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.569484+00:00"
    },
    {
      "template_id": "170391b86ab613ba",
      "name": "example_generate_code",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    engine = TemplateEngine(examples_dir={{STRING}})\n    engine.extract_templates()\n    \n    # Get a template\n    templates = engine.find_templates(category={{STRING}}, language={{STRING}})\n    \n    if templates:\n        template = templates[{{NUMBER}}]\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n        # Generate code\n        variables = {var: f{{STRING}} for var in template.variables}\n        generated = engine.generate_code(template.template_id, variables)\n        \n        if generated:\n            print(f{{STRING}})\n            print(f{{STRING}})\n            print({{STRING}} * {{NUMBER}})\n            # Show first {{NUMBER}} lines\n            lines = generated.code.split({{STRING}})[:{{NUMBER}}]\n            for line in lines:\n                print(line)\n            if len(generated.code.split({{STRING}})) > {{NUMBER}}:\n                print({{STRING}})\n            print({{STRING}} * {{NUMBER}})\n\n",
      "variables": [
        "category",
        "engine",
        "examples_dir",
        "generated",
        "language",
        "lines",
        "template",
        "templates",
        "variables"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.569617+00:00"
    },
    {
      "template_id": "67a8538185238832",
      "name": "example_performance_tracking",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    engine = TemplateEngine(examples_dir={{STRING}}, enable_cache=True)\n    \n    import time\n    \n    # Measure extraction time\n    start = time.time()\n    count = engine.extract_templates()\n    extraction_time = time.time() - start\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    # Generate code multiple times to test generation performance\n    templates = list(engine.templates.values())\n    if templates:\n        template = templates[{{NUMBER}}]\n        variables = {var: f{{STRING}} for var in template.variables}\n        \n        times = []\n        for _ in range({{NUMBER}}):\n            start = time.time()\n            engine.generate_code(template.template_id, variables)\n            times.append((time.time() - start) * {{NUMBER}})\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "count",
        "enable_cache",
        "engine",
        "examples_dir",
        "extraction_time",
        "start",
        "template",
        "templates",
        "times",
        "variables"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.569752+00:00"
    },
    {
      "template_id": "caebd5a50748b559",
      "name": "example_most_used_templates",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    engine = TemplateEngine(examples_dir={{STRING}})\n    engine.extract_templates()\n    \n    # Generate some code to create usage data\n    templates = list(engine.templates.values())\n    if templates:\n        # Use some templates multiple times\n        for i in range(min({{NUMBER}}, len(templates))):\n            template = templates[i]\n            variables = {var: f{{STRING}} for var in template.variables}\n            for _ in range(i + {{NUMBER}}):  # Use first template 1x, second 2x, third 3x\n                engine.generate_code(template.template_id, variables)\n    \n    # Get statistics\n    stats = engine.get_statistics()\n    \n    print({{STRING}})\n    for i, template_info in enumerate(stats[{{STRING}}], {{NUMBER}}):\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "engine",
        "examples_dir",
        "stats",
        "template",
        "templates",
        "variables"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.569889+00:00"
    },
    {
      "template_id": "175e77d50fca82d4",
      "name": "example_caching",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    import time\n    \n    # First run without cache\n    print({{STRING}})\n    engine1 = TemplateEngine(\n        examples_dir={{STRING}},\n        cache_dir={{STRING}},\n        enable_cache=True\n    )\n    start = time.time()\n    count1 = engine1.extract_templates(force_refresh=True)\n    time1 = time.time() - start\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    # Second run with cache\n    print({{STRING}})\n    engine2 = TemplateEngine(\n        examples_dir={{STRING}},\n        cache_dir={{STRING}},\n        enable_cache=True\n    )\n    start = time.time()\n    count2 = engine2.extract_templates(force_refresh=False)\n    time2 = time.time() - start\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    if time1 > {{NUMBER}}:\n        speedup = time1 / time2 if time2 > {{NUMBER}} else float({{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "cache_dir",
        "count1",
        "count2",
        "enable_cache",
        "engine1",
        "engine2",
        "examples_dir",
        "force_refresh",
        "speedup",
        "start",
        "time1",
        "time2"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570011+00:00"
    },
    {
      "template_id": "6baaead0c77e4057",
      "name": "example_template_details",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    engine = TemplateEngine(examples_dir={{STRING}})\n    engine.extract_templates()\n    \n    # Get a template\n    templates = list(engine.templates.values())\n    if templates:\n        template = templates[{{NUMBER}}]\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n        print(f{{STRING}})\n        print({{STRING}} * {{NUMBER}})\n        lines = template.pattern.split({{STRING}})[:{{NUMBER}}]\n        for line in lines:\n            print(line)\n        if len(template.pattern.split({{STRING}})) > {{NUMBER}}:\n            print({{STRING}})\n        print({{STRING}} * {{NUMBER}})\n\n",
      "variables": [
        "engine",
        "examples_dir",
        "lines",
        "template",
        "templates"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/template-engine-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570128+00:00"
    },
    {
      "template_id": "2c1ec9e2bf735dfc",
      "name": "detect_category_from_labels",
      "category": "function",
      "language": "python",
      "pattern": "label_map = {\n        {{STRING}}: {{STRING}},\n        {{STRING}}: {{STRING}},\n        {{STRING}}: {{STRING}},\n        {{STRING}}: {{STRING}},\n        {{STRING}}: {{STRING}},\n        {{STRING}}: {{STRING}}\n    }\n    \n    for label in labels:\n        if label.lower() in label_map:\n            return label_map[label.lower()]\n    \n    # Default to feature if no category label\n    return {{STRING}}\n\n",
      "variables": [
        "label_map"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/prompt-generator-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570354+00:00"
    },
    {
      "template_id": "a2e228ade7f36afa",
      "name": "extract_learning_context",
      "category": "function",
      "language": "python",
      "pattern": "learnings_path = Path(learnings_dir)\n    if not learnings_path.exists():\n        return []\n    \n    cutoff_date = datetime.now(timezone.utc).timestamp() - (days * {{NUMBER}})\n    recent_learnings = []\n    \n    # Find recent learning files\n    for file in learnings_path.glob({{STRING}}):\n        if file.stat().st_mtime < cutoff_date:\n            continue\n        \n        try:\n            with open(file) as f:\n                data = json.load(f)\n                \n                # Extract learnings or trends\n                if {{STRING}} in data and data[{{STRING}}]:\n                    recent_learnings.extend(data[{{STRING}}][:{{NUMBER}}])\n                elif {{STRING}} in data and data[{{STRING}}]:\n                    recent_learnings.extend(data[{{STRING}}][:{{NUMBER}}])\n        except Exception as e:\n            print(f{{STRING}}, file=sys.stderr)\n    \n    return recent_learnings[:{{NUMBER}}]  # Return top {{NUMBER}} most recent\n\n",
      "variables": [
        "cutoff_date",
        "data",
        "file",
        "learnings_path",
        "recent_learnings"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/prompt-generator-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570448+00:00"
    },
    {
      "template_id": "91f9fdec50b403ad",
      "name": "generate_enhanced_prompt",
      "category": "function",
      "language": "python",
      "pattern": "# Initialize generator\n    generator = PromptGenerator()\n    \n    # Detect category\n    category = detect_category_from_labels(labels)\n    print(f{{STRING}}, file=sys.stderr)\n    \n    # Extract learning context\n    learning_context = extract_learning_context()\n    if learning_context:\n        print(f{{STRING}}, file=sys.stderr)\n    \n    # Generate prompt\n    prompt, template_id = generator.generate_prompt(\n        issue_body=issue_body,\n        category=category,\n        agent=agent,\n        learning_context=learning_context if learning_context else None\n    )\n    \n    print(f{{STRING}}, file=sys.stderr)\n    \n    return {\n        {{STRING}}: prompt,\n        {{STRING}}: template_id,\n        {{STRING}}: category,\n        {{STRING}}: agent,\n        {{STRING}}: issue_number,\n        {{STRING}}: len(learning_context) if learning_context else {{NUMBER}}\n    }\n\n",
      "variables": [
        "agent",
        "category",
        "file",
        "generator",
        "issue_body",
        "learning_context",
        "template_id"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/prompt-generator-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570552+00:00"
    },
    {
      "template_id": "b406e8b1f0ad3684",
      "name": "record_task_outcome",
      "category": "function",
      "language": "python",
      "pattern": "generator = PromptGenerator()\n    \n    generator.record_outcome(\n        prompt_id=template_id,\n        issue_number=issue_number,\n        success=success,\n        resolution_time_hours=resolution_time_hours,\n        agent_used=agent,\n        error_type=error_type\n    )\n    \n    print(f{{STRING}}, file=sys.stderr)\n    \n    # Get updated performance\n    report = generator.get_performance_report()\n    if template_id in report[{{STRING}}]:\n        stats = report[{{STRING}}][template_id]\n        print(f{{STRING}}, file=sys.stderr)\n        print(f{{STRING}}, file=sys.stderr)\n\n",
      "variables": [
        "agent_used",
        "error_type",
        "file",
        "generator",
        "issue_number",
        "prompt_id",
        "report",
        "resolution_time_hours",
        "stats",
        "success"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/prompt-generator-integration.py",
      "extracted_at": "2025-11-16T03:28:03.570631+00:00"
    },
    {
      "template_id": "e3c3f118510678df",
      "name": "TextAnalysis",
      "category": "class",
      "language": "python",
      "pattern": "word_count: int\n    unique_words: int\n    most_common_word: Tuple[str, int]\n    average_word_length: float\n    \n    def __str__(self) -> str:\n        {{STRING}}{{STRING}}{{STRING}}\n        word, count = self.most_common_word\n        return (\n            f{{STRING}}\n            f{{STRING}}\n            f{{STRING}}\n            f{{STRING}}\n        )\n\n\ndef analyze_text(text: str) -> Optional[TextAnalysis]:\n    {{STRING}}{{STRING}}{{STRING}}\n    if not text or not text.strip():\n        return None\n    \n    words = text.lower().split()\n    word_frequencies = Counter(words)\n    total_characters = sum(len(word) for word in words)\n    \n    return TextAnalysis(\n        word_count=len(words),\n        unique_words=len(word_frequencies),\n        most_common_word=word_frequencies.most_common({{NUMBER}})[{{NUMBER}}],\n        average_word_length=total_characters / len(words)\n    )\n\n\ndef find_palindromes(words: List[str]) -> List[str]:\n    {{STRING}}{{STRING}}{{STRING}}\n    def is_palindrome(word: str) -> bool:\n        {{STRING}}{{STRING}}{{STRING}}\n        normalized = word.lower()\n        return normalized == normalized[::-{{NUMBER}}]\n    \n    palindromes = [word for word in words if is_palindrome(word)]\n    return sorted(palindromes, key=len, reverse=True)\n\n\ndef fibonacci_sequence(count: int) -> List[int]:\n    {{STRING}}{{STRING}}{{STRING}}\n    if count < {{NUMBER}}:\n        raise ValueError({{STRING}})\n    \n    if count == {{NUMBER}}:\n        return []\n    \n    if count == {{NUMBER}}:\n        return [{{NUMBER}}]\n    \n    sequence = [{{NUMBER}}, {{NUMBER}}]\n    while len(sequence) < count:\n        next_number = sequence[-{{NUMBER}}] + sequence[-{{NUMBER}}]\n        sequence.append(next_number)\n    \n    return sequence\n\n\ndef format_number_with_separators(number: int, separator: str = {{STRING}}) -> str:\n    {{STRING}}{{STRING}}{{STRING}}\n    number_str = str(abs(number))\n    groups = []\n    \n    for i in range(len(number_str), {{NUMBER}}, -{{NUMBER}}):\n        start = max({{NUMBER}}, i - {{NUMBER}})\n        groups.insert({{NUMBER}}, number_str[start:i])\n    \n    formatted = separator.join(groups)\n    return f{{STRING}} if number < {{NUMBER}} else formatted\n\n\ndef validate_email(email: str) -> bool:\n    {{STRING}}{{STRING}}{{STRING}}\n    if not email or {{STRING}} not in email:\n        return False\n    \n    local, domain = email.rsplit({{STRING}}, {{NUMBER}})\n    \n    if not local or not domain:\n        return False\n    \n    if {{STRING}} not in domain:\n        return False\n    \n    return True\n\n\ndef main():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}})\n    \n    # Text analysis demonstration\n    sample_text = {{STRING}}\n    analysis = analyze_text(sample_text)\n    if analysis:\n        print(f{{STRING}})\n        print(f{{STRING}})\n    \n    # Palindrome discovery\n    words = [{{STRING}}, {{STRING}}, {{STRING}}, {{STRING}}, {{STRING}}, {{STRING}}]\n    palindromes = find_palindromes(words)\n    print(f{{STRING}})\n    \n    # Fibonacci sequence\n    fib = fibonacci_sequence({{NUMBER}})\n    print(f{{STRING}})\n    \n    # Number formatting\n    big_number = {{NUMBER}}\n    formatted = format_number_with_separators(big_number)\n    print(f{{STRING}})\n    \n    # Email validation\n    test_emails = [{{STRING}}, {{STRING}}, {{STRING}}]\n    print({{STRING}})\n    for email in test_emails:\n        status = {{STRING}} if validate_email(email) else {{STRING}}\n        print(f{{STRING}})\n\n\nif __name__ == {{STRING}}:\n    main()\n",
      "variables": [
        "__name__",
        "analysis",
        "average_word_length",
        "big_number",
        "count",
        "domain",
        "fib",
        "formatted",
        "groups",
        "key",
        "most_common_word",
        "next_number",
        "normalized",
        "number_str",
        "palindromes",
        "reverse",
        "sample_text",
        "sequence",
        "start",
        "status",
        "str",
        "test_emails",
        "total_characters",
        "unique_words",
        "word_count",
        "word_frequencies",
        "words"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/code-poetry-showcase.py",
      "extracted_at": "2025-11-16T03:28:03.571622+00:00"
    },
    {
      "template_id": "f6c1a1d3a221f015",
      "name": "__init__",
      "category": "function",
      "language": "python",
      "pattern": "self.engine = EvaluationEngine(cache_dir=cache_dir)\n        self.workflow_registry = {}\n    \n    def register_expensive_workflow(self, name: str, workflow_fn, \n                                   dependencies=None, cache_ttl={{NUMBER}}):\n        {{STRING}}{{STRING}}{{STRING}}\n        self.workflow_registry[name] = {\n            {{STRING}}: workflow_fn,\n            {{STRING}}: dependencies or [],\n            {{STRING}}: cache_ttl\n        }\n        \n        self.engine.register_workflow(\n            node_id=name,\n            compute_fn=workflow_fn,\n            dependencies=dependencies or [],\n            cache_ttl=cache_ttl,\n            metadata={{{STRING}}: {{STRING}}}\n        )\n    \n    def run_workflow(self, name: str, force_refresh: bool = False):\n        {{STRING}}{{STRING}}{{STRING}}\n        if name not in self.workflow_registry:\n            raise ValueError(f{{STRING}})\n        \n        return self.engine.evaluate(name, force=force_refresh)\n    \n    def get_performance_report(self):\n        {{STRING}}{{STRING}}{{STRING}}\n        return {\n            {{STRING}}: self.engine.get_metrics(),\n            {{STRING}}: self.engine.get_summary(),\n            {{STRING}}: self.engine.visualize_graph()\n        }\n\n",
      "variables": [
        "bool",
        "cache_dir",
        "cache_ttl",
        "compute_fn",
        "dependencies",
        "engine",
        "force",
        "metadata",
        "node_id",
        "workflow_registry"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.571876+00:00"
    },
    {
      "template_id": "ed0ed191487a90d6",
      "name": "example_1_simple_caching",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Simulate expensive API call\n    call_count = [{{NUMBER}}]\n    \n    def fetch_github_data():\n        {{STRING}}{{STRING}}{{STRING}}\n        call_count[{{NUMBER}}] += {{NUMBER}}\n        print(f{{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})  # Simulate network delay\n        return {\n            {{STRING}}: [{{STRING}}, {{STRING}}, {{STRING}}],\n            {{STRING}}: {{NUMBER}},\n            {{STRING}}: time.time()\n        }\n    \n    # Register workflow with {{NUMBER}}-hour cache\n    optimizer.register_expensive_workflow(\n        {{STRING}},\n        fetch_github_data,\n        cache_ttl={{NUMBER}}\n    )\n    \n    # First call - hits API\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Second call - uses cache\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Verify caching worked\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    # Show performance\n    report = optimizer.get_performance_report()\n    print(f{{STRING}})\n\n",
      "variables": [
        "cache_ttl",
        "call_count",
        "optimizer",
        "report",
        "result1",
        "result2"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.572030+00:00"
    },
    {
      "template_id": "15331d43677837a1",
      "name": "example_2_dependency_chain",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Step {{NUMBER}}: Fetch raw data\n    def fetch_data():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: [{{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}]}\n    \n    # Step {{NUMBER}}: Clean and transform (depends on fetch)\n    def clean_data(fetch):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        values = fetch[{{STRING}}]\n        return {{{STRING}}: [v for v in values if v % {{NUMBER}} == {{NUMBER}}]}\n    \n    # Step {{NUMBER}}: Analyze (depends on clean)\n    def analyze_data(clean):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        values = clean[{{STRING}}]\n        return {\n            {{STRING}}: len(values),\n            {{STRING}}: sum(values),\n            {{STRING}}: sum(values) / len(values)\n        }\n    \n    # Step {{NUMBER}}: Generate report (depends on analyze)\n    def generate_report(analyze):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return f{{STRING}}\n    \n    # Register workflows with dependencies\n    optimizer.register_expensive_workflow({{STRING}}, fetch_data, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, clean_data, \n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, analyze_data,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_report,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    \n    # First run - everything executes\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Second run - everything cached\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Show dependency graph\n    print({{STRING}})\n    print(optimizer.engine.visualize_graph())\n\n",
      "variables": [
        "avg",
        "cache_ttl",
        "dependencies",
        "optimizer",
        "result1",
        "result2",
        "values"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.572266+00:00"
    },
    {
      "template_id": "20058fa325f902c1",
      "name": "example_3_conditional_evaluation",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # These workflows are expensive but may not be needed\n    def expensive_ml_training():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{STRING}}, {{STRING}}: {{NUMBER}}.{{NUMBER}}}\n    \n    def quick_analysis():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{STRING}}}\n    \n    def generate_simple_report(quick):  # Parameter matches dependency ID\n        print({{STRING}})\n        return f{{STRING}}\n    \n    def generate_advanced_report(quick, ml_training):  # Parameters match dependency IDs\n        print({{STRING}})\n        return f{{STRING}}\n    \n    # Register workflows\n    optimizer.register_expensive_workflow({{STRING}}, expensive_ml_training, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, quick_analysis, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_simple_report,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_advanced_report,\n                                         dependencies=[{{STRING}}, {{STRING}}], cache_ttl={{NUMBER}})\n    \n    # Run simple report - ML training NOT executed\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Run advanced report - NOW ML training executes\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    print({{STRING}})\n    print({{STRING}})\n\n",
      "variables": [
        "cache_ttl",
        "dependencies",
        "optimizer",
        "result1",
        "result2"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.572470+00:00"
    },
    {
      "template_id": "05bda44f19548d44",
      "name": "example_4_workflow_orchestrator_integration",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Simulate workflow-orchestrator.py patterns\n    def check_api_quota():\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{NUMBER}}, {{STRING}}: {{NUMBER}}}\n    \n    def calculate_burn_rate(quota_check):  # Parameter matches dependency ID\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: (quota_check[{{STRING}}] - quota_check[{{STRING}}]) / {{NUMBER}}.{{NUMBER}}}\n    \n    def recommend_schedule(burn_rate):  # Parameter matches dependency ID\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        rate = burn_rate[{{STRING}}]\n        \n        if rate < {{NUMBER}}:\n            mode = {{STRING}}\n        elif rate < {{NUMBER}}:\n            mode = {{STRING}}\n        else:\n            mode = {{STRING}}\n        \n        return {{{STRING}}: mode, {{STRING}}: rate}\n    \n    # Register workflows (simulating orchestrator logic)\n    optimizer.register_expensive_workflow({{STRING}}, check_api_quota, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, calculate_burn_rate,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, recommend_schedule,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    \n    # Multiple calls to get schedule - only computes once\n    print({{STRING}})\n    for i in range({{NUMBER}}):\n        result = optimizer.run_workflow({{STRING}})\n        print(f{{STRING}})\n    \n    # Show performance improvement\n    report = optimizer.get_performance_report()\n    summary = report[{{STRING}}]\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n\n",
      "variables": [
        "Mode",
        "Rate",
        "cache_ttl",
        "dependencies",
        "mode",
        "optimizer",
        "rate",
        "report",
        "result",
        "summary"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.572711+00:00"
    },
    {
      "template_id": "d01177e15ea4b8e5",
      "name": "WorkflowOptimizer",
      "category": "class",
      "language": "python",
      "pattern": "def __init__(self, cache_dir: str = None):\n        {{STRING}}{{STRING}}{{STRING}}\n        self.engine = EvaluationEngine(cache_dir=cache_dir)\n        self.workflow_registry = {}\n    \n    def register_expensive_workflow(self, name: str, workflow_fn, \n                                   dependencies=None, cache_ttl={{NUMBER}}):\n        {{STRING}}{{STRING}}{{STRING}}\n        self.workflow_registry[name] = {\n            {{STRING}}: workflow_fn,\n            {{STRING}}: dependencies or [],\n            {{STRING}}: cache_ttl\n        }\n        \n        self.engine.register_workflow(\n            node_id=name,\n            compute_fn=workflow_fn,\n            dependencies=dependencies or [],\n            cache_ttl=cache_ttl,\n            metadata={{{STRING}}: {{STRING}}}\n        )\n    \n    def run_workflow(self, name: str, force_refresh: bool = False):\n        {{STRING}}{{STRING}}{{STRING}}\n        if name not in self.workflow_registry:\n            raise ValueError(f{{STRING}})\n        \n        return self.engine.evaluate(name, force=force_refresh)\n    \n    def get_performance_report(self):\n        {{STRING}}{{STRING}}{{STRING}}\n        return {\n            {{STRING}}: self.engine.get_metrics(),\n            {{STRING}}: self.engine.get_summary(),\n            {{STRING}}: self.engine.visualize_graph()\n        }\n\n\ndef example_1_simple_caching():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Simulate expensive API call\n    call_count = [{{NUMBER}}]\n    \n    def fetch_github_data():\n        {{STRING}}{{STRING}}{{STRING}}\n        call_count[{{NUMBER}}] += {{NUMBER}}\n        print(f{{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})  # Simulate network delay\n        return {\n            {{STRING}}: [{{STRING}}, {{STRING}}, {{STRING}}],\n            {{STRING}}: {{NUMBER}},\n            {{STRING}}: time.time()\n        }\n    \n    # Register workflow with {{NUMBER}}-hour cache\n    optimizer.register_expensive_workflow(\n        {{STRING}},\n        fetch_github_data,\n        cache_ttl={{NUMBER}}\n    )\n    \n    # First call - hits API\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Second call - uses cache\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Verify caching worked\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    # Show performance\n    report = optimizer.get_performance_report()\n    print(f{{STRING}})\n\n\ndef example_2_dependency_chain():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Step {{NUMBER}}: Fetch raw data\n    def fetch_data():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: [{{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}, {{NUMBER}}]}\n    \n    # Step {{NUMBER}}: Clean and transform (depends on fetch)\n    def clean_data(fetch):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        values = fetch[{{STRING}}]\n        return {{{STRING}}: [v for v in values if v % {{NUMBER}} == {{NUMBER}}]}\n    \n    # Step {{NUMBER}}: Analyze (depends on clean)\n    def analyze_data(clean):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        values = clean[{{STRING}}]\n        return {\n            {{STRING}}: len(values),\n            {{STRING}}: sum(values),\n            {{STRING}}: sum(values) / len(values)\n        }\n    \n    # Step {{NUMBER}}: Generate report (depends on analyze)\n    def generate_report(analyze):  # Parameter name must match dependency ID\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return f{{STRING}}\n    \n    # Register workflows with dependencies\n    optimizer.register_expensive_workflow({{STRING}}, fetch_data, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, clean_data, \n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, analyze_data,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_report,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    \n    # First run - everything executes\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Second run - everything cached\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Show dependency graph\n    print({{STRING}})\n    print(optimizer.engine.visualize_graph())\n\n\ndef example_3_conditional_evaluation():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # These workflows are expensive but may not be needed\n    def expensive_ml_training():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{STRING}}, {{STRING}}: {{NUMBER}}.{{NUMBER}}}\n    \n    def quick_analysis():\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{STRING}}}\n    \n    def generate_simple_report(quick):  # Parameter matches dependency ID\n        print({{STRING}})\n        return f{{STRING}}\n    \n    def generate_advanced_report(quick, ml_training):  # Parameters match dependency IDs\n        print({{STRING}})\n        return f{{STRING}}\n    \n    # Register workflows\n    optimizer.register_expensive_workflow({{STRING}}, expensive_ml_training, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, quick_analysis, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_simple_report,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, generate_advanced_report,\n                                         dependencies=[{{STRING}}, {{STRING}}], cache_ttl={{NUMBER}})\n    \n    # Run simple report - ML training NOT executed\n    print({{STRING}})\n    result1 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    # Run advanced report - NOW ML training executes\n    print({{STRING}})\n    result2 = optimizer.run_workflow({{STRING}})\n    print(f{{STRING}})\n    \n    print({{STRING}})\n    print({{STRING}})\n\n\ndef example_4_workflow_orchestrator_integration():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    optimizer = WorkflowOptimizer()\n    \n    # Simulate workflow-orchestrator.py patterns\n    def check_api_quota():\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: {{NUMBER}}, {{STRING}}: {{NUMBER}}}\n    \n    def calculate_burn_rate(quota_check):  # Parameter matches dependency ID\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        return {{{STRING}}: (quota_check[{{STRING}}] - quota_check[{{STRING}}]) / {{NUMBER}}.{{NUMBER}}}\n    \n    def recommend_schedule(burn_rate):  # Parameter matches dependency ID\n        {{STRING}}{{STRING}}{{STRING}}\n        print({{STRING}})\n        time.sleep({{NUMBER}}.{{NUMBER}})\n        rate = burn_rate[{{STRING}}]\n        \n        if rate < {{NUMBER}}:\n            mode = {{STRING}}\n        elif rate < {{NUMBER}}:\n            mode = {{STRING}}\n        else:\n            mode = {{STRING}}\n        \n        return {{{STRING}}: mode, {{STRING}}: rate}\n    \n    # Register workflows (simulating orchestrator logic)\n    optimizer.register_expensive_workflow({{STRING}}, check_api_quota, cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, calculate_burn_rate,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    optimizer.register_expensive_workflow({{STRING}}, recommend_schedule,\n                                         dependencies=[{{STRING}}], cache_ttl={{NUMBER}})\n    \n    # Multiple calls to get schedule - only computes once\n    print({{STRING}})\n    for i in range({{NUMBER}}):\n        result = optimizer.run_workflow({{STRING}})\n        print(f{{STRING}})\n    \n    # Show performance improvement\n    report = optimizer.get_performance_report()\n    summary = report[{{STRING}}]\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n\n\ndef main():\n    {{STRING}}{{STRING}}{{STRING}}\n    print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}})\n    \n    try:\n        example_1_simple_caching()\n        example_2_dependency_chain()\n        example_3_conditional_evaluation()\n        example_4_workflow_orchestrator_integration()\n        \n        print({{STRING}} + {{STRING}}*{{NUMBER}})\n        print({{STRING}})\n        print({{STRING}}*{{NUMBER}} + {{STRING}})\n        \n    except Exception as e:\n        print(f{{STRING}})\n        import traceback\n        traceback.print_exc()\n        sys.exit({{NUMBER}})\n\n\nif __name__ == {{STRING}}:\n    main()\n",
      "variables": [
        "Mode",
        "Rate",
        "__name__",
        "avg",
        "bool",
        "cache_dir",
        "cache_ttl",
        "call_count",
        "compute_fn",
        "dependencies",
        "engine",
        "force",
        "metadata",
        "mode",
        "node_id",
        "optimizer",
        "rate",
        "report",
        "result",
        "result1",
        "result2",
        "str",
        "summary",
        "values",
        "workflow_registry"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/lazy_evaluation_integration.py",
      "extracted_at": "2025-11-16T03:28:03.573894+00:00"
    },
    {
      "template_id": "17465995fdedfd9c",
      "name": "example_retry_logic",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    # Configure aggressive retry for critical operations\n    retry_config = RetryConfig(\n        max_attempts={{NUMBER}},\n        initial_delay={{NUMBER}}.{{NUMBER}},\n        max_delay={{NUMBER}}.{{NUMBER}},\n        backoff_factor={{NUMBER}}.{{NUMBER}},\n        strategy=RetryStrategy.EXPONENTIAL\n    )\n    \n    client = GitHubAPIClient(retry_config=retry_config)\n    \n    try:\n        # This will automatically retry on transient failures\n        issues = client.get({{STRING}}, params={\n            {{STRING}}: {{STRING}},\n            {{STRING}}: {{NUMBER}}\n        })\n        \n        print(f{{STRING}})\n        for issue in issues[:{{NUMBER}}]:\n            print(f{{STRING}})\n        \n    except GitHubAPIException as e:\n        print(f{{STRING}})\n    \n    print()\n\n",
      "variables": [
        "backoff_factor",
        "client",
        "initial_delay",
        "issues",
        "max_attempts",
        "max_delay",
        "params",
        "retry_config",
        "strategy"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/github_integration_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574197+00:00"
    },
    {
      "template_id": "adc9fe7360f05b68",
      "name": "example_error_handling",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    from api_coordination_hub import RateLimitExceeded, CircuitBreakerOpen\n    \n    hub = get_hub()\n    hub.register_api({{STRING}}, APIConfig(\n        rate_limit={{NUMBER}},\n        time_window={{NUMBER}},\n        circuit_breaker_threshold={{NUMBER}}\n    ))\n    \n    call_count = [{{NUMBER}}]\n    \n    @hub.coordinate({{STRING}})\n    def unreliable_call(should_fail=False):\n        call_count[{{NUMBER}}] += {{NUMBER}}\n        if should_fail:\n            raise Exception({{STRING}})\n        return f{{STRING}}\n    \n    print({{STRING}})\n    for i in range({{NUMBER}}):\n        try:\n            result = unreliable_call()\n            print(f{{STRING}})\n        except Exception as e:\n            print(f{{STRING}})\n    \n    print({{STRING}})\n    for i in range({{NUMBER}}):\n        try:\n            result = unreliable_call()\n            print(f{{STRING}})\n        except RateLimitExceeded as e:\n            print(f{{STRING}})\n        except Exception as e:\n            print(f{{STRING}})\n    \n    print({{STRING}})\n    # Reset for clean test\n    hub.reset_circuit_breaker({{STRING}})\n    \n    # Cause failures\n    for i in range({{NUMBER}}):\n        try:\n            result = unreliable_call(should_fail=True)\n            print(f{{STRING}})\n        except CircuitBreakerOpen as e:\n            print(f{{STRING}})\n        except Exception as e:\n            print(f{{STRING}})\n    \n    print()\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    return True\n\n",
      "variables": [
        "call_count",
        "circuit_breaker_threshold",
        "hub",
        "rate_limit",
        "result",
        "should_fail",
        "time_window"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577425+00:00"
    },
    {
      "template_id": "ef9dd8c8280098a0",
      "name": "example_graphql",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    client = GitHubAPIClient()\n    \n    query = {{STRING}}{{STRING}}{{STRING}}\n    \n    try:\n        result = client.graphql(query, variables={\n            {{STRING}}: {{STRING}},\n            {{STRING}}: {{STRING}}\n        })\n        \n        repo = result[{{STRING}}]\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n        print({{STRING}})\n        for issue in repo[{{STRING}}][{{STRING}}]:\n            print(f{{STRING}})\n        \n    except GitHubAPIException as e:\n        print(f{{STRING}})\n    except Exception as e:\n        print(f{{STRING}})\n    \n    print()\n\n",
      "variables": [
        "client",
        "query",
        "repo",
        "result",
        "variables"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/github_integration_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574416+00:00"
    },
    {
      "template_id": "ddf2a8e06044f326",
      "name": "example_rate_limit_monitoring",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    client = GitHubAPIClient()\n    \n    try:\n        rate_limit = client.get({{STRING}})\n        \n        for resource_type, limits in rate_limit[{{STRING}}].items():\n            remaining = limits[{{STRING}}]\n            total = limits[{{STRING}}]\n            percentage = (remaining / total * {{NUMBER}}) if total > {{NUMBER}} else {{NUMBER}}\n            \n            print(f{{STRING}})\n            print(f{{STRING}})\n            \n            if remaining < {{NUMBER}}:\n                print(f{{STRING}})\n        \n    except GitHubAPIException as e:\n        print(f{{STRING}})\n    \n    print()\n\n",
      "variables": [
        "client",
        "percentage",
        "rate_limit",
        "remaining",
        "total"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/github_integration_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574499+00:00"
    },
    {
      "template_id": "1f0ba11c33c43e7a",
      "name": "example_bulk_operations",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} * {{NUMBER}})\n    print({{STRING}})\n    print({{STRING}} * {{NUMBER}})\n    \n    client = GitHubAPIClient(retry_config=RetryConfig(max_attempts={{NUMBER}}))\n    \n    # List of popular repositories\n    repos = [\n        {{STRING}},\n        {{STRING}},\n        {{STRING}}\n    ]\n    \n    results = []\n    \n    for repo_name in repos:\n        try:\n            repo = client.get(f{{STRING}})\n            results.append({\n                {{STRING}}: repo[{{STRING}}],\n                {{STRING}}: repo[{{STRING}}],\n                {{STRING}}: repo[{{STRING}}]\n            })\n            \n        except GitHubAPIException as e:\n            if e.error.is_rate_limited:\n                print(f{{STRING}})\n            else:\n                print(f{{STRING}})\n    \n    print(f{{STRING}})\n    \n    # Sort by stars\n    results.sort(key=lambda x: x[{{STRING}}], reverse=True)\n    \n    print({{STRING}})\n    for repo in results:\n        print(f{{STRING}})\n    \n    print()\n\n",
      "variables": [
        "client",
        "key",
        "max_attempts",
        "repo",
        "repos",
        "results",
        "retry_config",
        "reverse"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/github_integration_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574623+00:00"
    },
    {
      "template_id": "46a71d0fd6543243",
      "name": "example_1_simple_task",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Create plan for simple task\n    plan, chain = system.create_hierarchical_plan(\n        task_id={{STRING}},\n        task_description={{STRING}}\n    )\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    for level in chain.hierarchy:\n        print(f{{STRING}})\n        if {{STRING}} in level:\n            print(f{{STRING}})\n            print(f{{STRING}})\n\n",
      "variables": [
        "chain",
        "system",
        "task_description",
        "task_id"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.574906+00:00"
    },
    {
      "template_id": "fe1f7b028d310bdd",
      "name": "example_2_complex_feature",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Create plan for complex task\n    plan, chain = system.create_hierarchical_plan(\n        task_id={{STRING}},\n        task_description={{STRING}}{{STRING}}{{STRING}},\n        task_context={{{STRING}}: [{{STRING}}, {{STRING}}, {{STRING}}]}\n    )\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    for i, subtask in enumerate(plan.sub_tasks, {{NUMBER}}):\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "chain",
        "system",
        "task_context",
        "task_description",
        "task_id"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575020+00:00"
    },
    {
      "template_id": "d3f31001d4a8bcab",
      "name": "example_3_delegation",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Get coordinators and specialists\n    coordinators = system.get_coordinator_agents()\n    specialists = system.get_specialist_agents()\n    \n    if coordinators and specialists:\n        coordinator_id = coordinators[{{NUMBER}}]\n        specialist_id = specialists[{{NUMBER}}]\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n        # Delegate task\n        delegation = system.delegate_task(\n            from_agent=coordinator_id,\n            to_agent=specialist_id,\n            task_description={{STRING}},\n            context={{{STRING}}: {{STRING}}, {{STRING}}: {{STRING}}}\n        )\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "context",
        "coordinator_id",
        "coordinators",
        "delegation",
        "from_agent",
        "specialist_id",
        "specialists",
        "system",
        "task_description",
        "to_agent"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575162+00:00"
    },
    {
      "template_id": "20a62052d2efd7b1",
      "name": "example_4_escalation",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Get workers\n    workers = system.get_worker_agents()\n    \n    if workers:\n        worker_id = workers[{{NUMBER}}]\n        worker_tier = system.agent_tiers[worker_id]\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n        # Escalate task\n        escalation = system.escalate_task(\n            from_agent=worker_id,\n            task_id={{STRING}},\n            reason={{STRING}}\n        )\n        \n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "escalation",
        "from_agent",
        "reason",
        "system",
        "task_id",
        "worker_id",
        "worker_tier",
        "workers"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575276+00:00"
    },
    {
      "template_id": "bacb0fa5d46b09dd",
      "name": "example_5_hierarchy_overview",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Get summary\n    summary = system.get_hierarchy_summary()\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    for role, count in summary[{{STRING}}].items():\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    for agent in summary[{{STRING}}]:\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    for agent in summary[{{STRING}}]:\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    for agent in summary[{{STRING}}]:\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    stats = summary[{{STRING}}]\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n\n",
      "variables": [
        "stats",
        "summary",
        "system"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575380+00:00"
    },
    {
      "template_id": "a0d26abd75cd5a90",
      "name": "example_6_role_filtering",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Get specialists with specific specialization\n    print({{STRING}})\n    engineers = system.get_specialist_agents({{STRING}})\n    for agent_id in engineers:\n        tier = system.agent_tiers[agent_id]\n        agent = system.base_coordinator.agents[agent_id]\n        score = agent.get({{STRING}}, {}).get({{STRING}}, {{NUMBER}})\n        print(f{{STRING}})\n    \n    print({{STRING}})\n    perf_workers = system.get_worker_agents({{STRING}})\n    for agent_id in perf_workers:\n        tier = system.agent_tiers[agent_id]\n        agent = system.base_coordinator.agents[agent_id]\n        score = agent.get({{STRING}}, {}).get({{STRING}}, {{NUMBER}})\n        print(f{{STRING}})\n\n",
      "variables": [
        "agent",
        "engineers",
        "perf_workers",
        "score",
        "system",
        "tier"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575474+00:00"
    },
    {
      "template_id": "ea087c3a6e8b5b61",
      "name": "example_7_multi_level_coordination",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    system = HierarchicalAgentSystem()\n    \n    # Simulate a complex task that requires all three tiers\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    \n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    \n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    print({{STRING}})\n    \n    print({{STRING}})\n    coordinators = system.get_coordinator_agents()\n    specialists = system.get_specialist_agents()\n    workers = system.get_worker_agents()\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n\n",
      "variables": [
        "coordinators",
        "specialists",
        "system",
        "workers"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hierarchical_agent_system_examples.py",
      "extracted_at": "2025-11-16T03:28:03.575624+00:00"
    },
    {
      "template_id": "a0cff45c45160637",
      "name": "generate_tools_from_learnings_book",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}})\n    print()\n    \n    # Initialize generator\n    generator = HNCodeGenerator()\n    \n    # Read learnings book\n    book_dir = Path(__file__).parent.parent.parent / {{STRING}} / {{STRING}}\n    \n    if not book_dir.exists():\n        print({{STRING}})\n        return\n    \n    # Check AI/ML chapter\n    ai_ml_file = book_dir / {{STRING}}\n    \n    if ai_ml_file.exists():\n        print({{STRING}})\n        \n        # In a real implementation, we{{STRING}}ll generate based on common AI topics\n        \n        ai_topics = [\n            ({{STRING}}, {{STRING}}, {{STRING}}),\n            ({{STRING}}, {{STRING}}, {{STRING}}),\n            ({{STRING}}, {{STRING}}, {{STRING}}),\n        ]\n        \n        print()\n        print({{STRING}})\n        print()\n        \n        for description, class_name, context_name in ai_topics:\n            generated = generator.generate_code(\n                description,\n                context={\n                    {{STRING}}: class_name,\n                    {{STRING}}: context_name\n                }\n            )\n            \n            if generated:\n                print(f{{STRING}})\n                print(f{{STRING}})\n                print(f{{STRING}})\n                print()\n    \n    # Check Programming chapter\n    prog_file = book_dir / {{STRING}}\n    \n    if prog_file.exists():\n        print({{STRING}})\n        print()\n        \n        prog_topics = [\n            ({{STRING}}, {{STRING}}, {{STRING}}),\n            ({{STRING}}, {{STRING}}, {{STRING}}),\n        ]\n        \n        print({{STRING}})\n        print()\n        \n        for description, class_name, context_name in prog_topics:\n            generated = generator.generate_code(\n                description,\n                context={\n                    {{STRING}}: class_name,\n                    {{STRING}}: context_name\n                }\n            )\n            \n            if generated:\n                print(f{{STRING}})\n                print(f{{STRING}})\n                print(f{{STRING}})\n                print()\n    \n    # Final statistics\n    print({{STRING}}*{{NUMBER}})\n    stats = generator.get_statistics()\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print({{STRING}}*{{NUMBER}})\n\n\nif __name__ == {{STRING}}:\n    generate_tools_from_learnings_book()\n",
      "variables": [
        "__name__",
        "ai_ml_file",
        "ai_topics",
        "book_dir",
        "context",
        "generated",
        "generator",
        "prog_file",
        "prog_topics",
        "stats"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/hn_code_generator_integration.py",
      "extracted_at": "2025-11-16T03:28:03.576041+00:00"
    },
    {
      "template_id": "90034ccbbba4ae22",
      "name": "print_section",
      "category": "function",
      "language": "python",
      "pattern": "print(f{{STRING}})\n    print(f{{STRING}})\n    print({{STRING}}*{{NUMBER}})\n\n",
      "variables": [],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/nl-to-code-demo.py",
      "extracted_at": "2025-11-16T03:28:03.576125+00:00"
    },
    {
      "template_id": "058ab471e72c813f",
      "name": "demo_case",
      "category": "function",
      "language": "python",
      "pattern": "print(f{{STRING}})\n    print(f{{STRING}})\n    \n    result = translator.translate(issue_text)\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    for entity in result.entities[:{{NUMBER}}]:  # Show first {{NUMBER}}\n        print(f{{STRING}})\n    if len(result.entities) > {{NUMBER}}:\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    for file in result.file_suggestions[:{{NUMBER}}]:  # Show first {{NUMBER}}\n        print(f{{STRING}})\n    \n    print(f{{STRING}})\n    for i, step in enumerate(result.implementation_plan[:{{NUMBER}}], {{NUMBER}}):  # Show first {{NUMBER}} steps\n        print(f{{STRING}})\n    if len(result.implementation_plan) > {{NUMBER}}:\n        print(f{{STRING}})\n\n",
      "variables": [
        "result"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/nl-to-code-demo.py",
      "extracted_at": "2025-11-16T03:28:03.576229+00:00"
    },
    {
      "template_id": "a07da217f01fb19f",
      "name": "example_github_integration",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    # Get hub and register GitHub API\n    hub = get_hub()\n    hub.register_api({{STRING}}, APIConfig(\n        rate_limit={{NUMBER}},\n        time_window={{NUMBER}},\n        circuit_breaker_threshold={{NUMBER}},\n        priority={{NUMBER}}\n    ))\n    \n    # Create GitHub client\n    client = GitHubAPIClient()\n    \n    # Wrap GitHub calls with coordination\n    @hub.coordinate({{STRING}})\n    def get_repo_info(owner, repo):\n        {{STRING}}{{STRING}}{{STRING}}\n        return client.get(f{{STRING}})\n    \n    @hub.coordinate({{STRING}})\n    def list_issues(owner, repo, state={{STRING}}):\n        {{STRING}}{{STRING}}{{STRING}}\n        return client.get(f{{STRING}}, params={{{STRING}}: state})\n    \n    try:\n        # Make coordinated API calls\n        print({{STRING}})\n        repo = get_repo_info({{STRING}}, {{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print()\n        \n        print({{STRING}})\n        issues = list_issues({{STRING}}, {{STRING}}, state={{STRING}})\n        print(f{{STRING}})\n        for issue in issues[:{{NUMBER}}]:\n            print(f{{STRING}})\n        print()\n        \n        # Show metrics\n        metrics = hub.get_metrics({{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        print(f{{STRING}})\n        \n    except Exception as e:\n        print(f{{STRING}})\n        return False\n    \n    return True\n\n",
      "variables": [
        "circuit_breaker_threshold",
        "client",
        "hub",
        "issues",
        "metrics",
        "params",
        "priority",
        "rate_limit",
        "repo",
        "state",
        "time_window"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577041+00:00"
    },
    {
      "template_id": "9161a920375f3d66",
      "name": "example_multi_api_coordination",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    hub = get_hub()\n    \n    # Register multiple APIs with different configurations\n    hub.register_api({{STRING}}, APIConfig(\n        rate_limit={{NUMBER}},\n        time_window={{NUMBER}},\n        priority={{NUMBER}}\n    ))\n    \n    hub.register_api({{STRING}}, APIConfig(\n        rate_limit={{NUMBER}},\n        time_window={{NUMBER}},\n        priority={{NUMBER}}\n    ))\n    \n    hub.register_api({{STRING}}, APIConfig(\n        rate_limit={{NUMBER}},\n        time_window={{NUMBER}},\n        priority={{NUMBER}}\n    ))\n    \n    # Create mock functions for demonstration\n    @hub.coordinate({{STRING}})\n    def fetch_github_data():\n        return {{{STRING}}: {{STRING}}, {{STRING}}: {{STRING}}}\n    \n    @hub.coordinate({{STRING}})\n    def fetch_web_data():\n        return {{{STRING}}: {{STRING}}, {{STRING}}: {{STRING}}}\n    \n    @hub.coordinate({{STRING}})\n    def store_data(data):\n        return {{{STRING}}: True, {{STRING}}: len(data)}\n    \n    try:\n        # Orchestrate workflow\n        print({{STRING}})\n        \n        gh_data = fetch_github_data()\n        print(f{{STRING}})\n        \n        web_data = fetch_web_data()\n        print(f{{STRING}})\n        \n        result = store_data({**gh_data, **web_data})\n        print(f{{STRING}})\n        print()\n        \n        # Show status for all APIs\n        print({{STRING}})\n        for api_name in [{{STRING}}, {{STRING}}, {{STRING}}]:\n            health = hub.get_health_status(api_name)\n            tokens = hub.get_available_tokens(api_name)\n            circuit = hub.get_circuit_state(api_name)\n            print(f{{STRING}})\n        \n    except Exception as e:\n        print(f{{STRING}})\n        return False\n    \n    return True\n\n",
      "variables": [
        "circuit",
        "gh_data",
        "health",
        "hub",
        "priority",
        "rate_limit",
        "result",
        "time_window",
        "tokens",
        "web_data"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577236+00:00"
    },
    {
      "template_id": "d313d8dc71dad9c1",
      "name": "example_metrics_export",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    hub = get_hub()\n    \n    # Ensure APIs are registered\n    if not hub.is_registered({{STRING}}):\n        hub.register_api({{STRING}}, APIConfig(rate_limit={{NUMBER}}))\n    \n    import time\n    \n    @hub.coordinate({{STRING}})\n    def monitored_call(latency={{NUMBER}}.{{NUMBER}}):\n        time.sleep(latency)\n        return {{STRING}}\n    \n    print({{STRING}})\n    for i in range({{NUMBER}}):\n        try:\n            monitored_call(latency={{NUMBER}}.{{NUMBER}})\n        except:\n            pass\n    \n    print({{STRING}})\n    print()\n    \n    # Get metrics\n    metrics = hub.get_metrics({{STRING}})\n    print({{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print(f{{STRING}})\n    print()\n    \n    # Export to file\n    export_path = {{STRING}}\n    hub.export_metrics(export_path)\n    print(f{{STRING}})\n    \n    # Read back to verify\n    import json\n    with open(export_path, {{STRING}}) as f:\n        exported = json.load(f)\n    \n    print(f{{STRING}})\n    print(f{{STRING}})\n    \n    return True\n\n",
      "variables": [
        "export_path",
        "exported",
        "hub",
        "latency",
        "metrics",
        "rate_limit"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577588+00:00"
    },
    {
      "template_id": "73a92cc647b4ff40",
      "name": "example_status_dashboard",
      "category": "function",
      "language": "python",
      "pattern": "print({{STRING}} + {{STRING}}*{{NUMBER}})\n    print({{STRING}})\n    print({{STRING}}*{{NUMBER}} + {{STRING}})\n    \n    hub = get_hub()\n    \n    # Register multiple APIs if not already registered\n    api_configs = {\n        {{STRING}}: APIConfig(rate_limit={{NUMBER}}, time_window={{NUMBER}}, priority={{NUMBER}}),\n        {{STRING}}: APIConfig(rate_limit={{NUMBER}}, time_window={{NUMBER}}, priority={{NUMBER}}),\n        {{STRING}}: APIConfig(rate_limit={{NUMBER}}, time_window={{NUMBER}}, priority={{NUMBER}})\n    }\n    \n    for name, config in api_configs.items():\n        if not hub.is_registered(name):\n            hub.register_api(name, config)\n    \n    # Print status dashboard\n    hub.print_status()\n    \n    return True\n\n",
      "variables": [
        "api_configs",
        "hub",
        "priority",
        "rate_limit",
        "time_window"
      ],
      "metadata": {},
      "usage_count": 0,
      "success_rate": 1.0,
      "avg_generation_time_ms": 0.0,
      "source_file": "tools/examples/api_coordination_hub_examples.py",
      "extracted_at": "2025-11-16T03:28:03.577656+00:00"
    }
  ],
  "metrics": {
    "total_generations": 0,
    "avg_generation_time_ms": 0.0,
    "template_usage": {},
    "extraction_stats": {
      "last_extraction": "2025-11-16T03:28:03.577902+00:00",
      "extraction_time_seconds": 0.010766,
      "templates_extracted": 62,
      "files_scanned": 20
    }
  },
  "last_updated": "2025-11-16T03:28:03.578326+00:00"
}