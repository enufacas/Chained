# PR Failure Learning System

## Overview

The PR Failure Learning System is an automated AI agent that learns from failed pull requests to improve future code generation. Built by **@engineer-master**, it systematically collects PR failure data, analyzes patterns, and generates actionable improvement suggestions for AI agents.

## üéØ Purpose

This system addresses a critical need in autonomous AI development: **learning from mistakes**. By analyzing why PRs fail (CI failures, test failures, review rejections, merge conflicts), the system helps AI agents:

- Identify common failure patterns
- Understand root causes
- Generate targeted improvements
- Track progress over time
- Reduce failure rates systematically

## üèóÔ∏è Architecture

### Components

1. **PR Failure Collector** (`tools/pr-failure-learner.py --collect`)
   - Fetches closed, unmerged PRs from GitHub API
   - Extracts failure details (check runs, reviews, file changes)
   - Identifies agent associations
   - Stores structured failure data

2. **Pattern Analyzer** (`tools/pr-failure-learner.py --analyze`)
   - Groups failures by type (CI, test, review, conflict)
   - Identifies common issues across failures
   - Calculates confidence scores
   - Generates statistical insights

3. **Improvement Suggester** (`tools/pr-failure-learner.py --suggest`)
   - Maps patterns to actionable suggestions
   - Provides agent-specific recommendations
   - Tracks failure frequency by agent
   - Generates improvement roadmap

4. **Workflow Integration** (`.github/workflows/pr-failure-learning.yml`)
   - Runs weekly to collect and analyze
   - Updates agent performance metrics
   - Creates learning summary issues
   - Commits insights to repository

## üìä Data Model

### PRFailure
```python
@dataclass
class PRFailure:
    pr_number: int
    title: str
    author: str
    agent_id: Optional[str]
    agent_specialization: Optional[str]
    created_at: str
    closed_at: Optional[str]
    failure_type: str  # ci_failure, test_failure, review_rejection, merge_conflict
    failure_details: Dict[str, Any]
    check_runs: List[Dict[str, Any]]
    review_comments: List[Dict[str, Any]]
    files_changed: int
    additions: int
    deletions: int
    labels: List[str]
```

### FailurePattern
```python
@dataclass
class FailurePattern:
    pattern_type: str
    occurrences: int
    affected_agents: List[str]
    common_issues: List[str]
    suggested_improvements: List[str]
    confidence_score: float
```

## üöÄ Usage

### Collect PR Failures
```bash
# Collect failures from last 30 days
python tools/pr-failure-learner.py --collect --since 30 --verbose

# Collect from last 7 days
python tools/pr-failure-learner.py --collect --since 7
```

### Analyze Patterns
```bash
# Analyze and display results
python tools/pr-failure-learner.py --analyze --verbose

# Save analysis to file
python tools/pr-failure-learner.py --analyze --output learnings/analysis.json
```

### Generate Suggestions
```bash
# Get suggestions for all agents
python tools/pr-failure-learner.py --suggest

# Get suggestions for specific agent
python tools/pr-failure-learner.py --suggest --agent agent-123
```

### Combined Workflow
```bash
# Complete learning cycle
python tools/pr-failure-learner.py --collect --since 30 --verbose
python tools/pr-failure-learner.py --analyze --output analysis.json
python tools/pr-failure-learner.py --suggest > suggestions.json
```

## üîÑ Automated Workflow

The system runs automatically via GitHub Actions:

### Triggers
- **Weekly**: Every Sunday at midnight UTC (scheduled analysis)
- **PR Closed**: When any PR is closed (incremental collection)
- **Manual**: Via workflow_dispatch for testing

### Workflow Steps
1. Collect PR failures from GitHub API
2. Analyze patterns and identify trends
3. Generate improvement suggestions per agent
4. Update agent performance metrics
5. Commit learning data to repository
6. Create weekly summary issue (scheduled runs only)

## üìÅ File Structure

```
learnings/
‚îú‚îÄ‚îÄ pr_failures.json              # All collected PR failures
‚îú‚îÄ‚îÄ pr_failure_analysis_*.json    # Analysis results with patterns
‚îî‚îÄ‚îÄ pr_improvement_suggestions_*.json  # Agent-specific suggestions

.github/agent-system/metrics/
‚îî‚îÄ‚îÄ agent-*/
    ‚îî‚îÄ‚îÄ pr_failure_insights_*.json  # Agent-specific insights
```

## üéì Learning Categories

### Failure Types

1. **CI Failure** - Continuous integration checks failed
   - Build errors
   - Linting issues
   - Configuration problems

2. **Test Failure** - Test suite failures
   - Unit test failures
   - Integration test failures
   - Coverage drops

3. **Review Rejection** - PR closed during review
   - Missing tests
   - Security concerns
   - Code quality issues
   - Missing documentation

4. **Merge Conflict** - Conflicts with target branch
   - Outdated branch
   - Conflicting changes
   - Large changeset issues

### Common Issues Detected

- Repeated check failures (same test/check failing multiple times)
- Large changesets (>20 files changed)
- Review concerns (tests, security, docs, style)
- Temporal patterns (certain times/days have more failures)

### Improvement Suggestions

**For CI/Test Failures:**
- Run tests locally before creating PR
- Ensure CI environment matches local setup
- Add comprehensive test coverage
- Use pre-commit hooks

**For Review Rejections:**
- Include tests with all PRs
- Update documentation for changes
- Run linter before submission
- Review security implications
- Follow code style guidelines

**For Merge Conflicts:**
- Sync with main branch regularly
- Keep PR scope small
- Rebase frequently for long-lived PRs
- Break large changes into smaller PRs

## üìà Metrics Integration

The system integrates with the agent performance metrics:

```json
{
  "agent_id": "agent-123",
  "total_failures": 5,
  "failure_types": {
    "test_failure": 3,
    "review_rejection": 2
  },
  "improvements": [
    "Include comprehensive tests with all PRs",
    "Run tests locally before creating PR",
    "Update documentation for code changes"
  ]
}
```

These insights influence:
- Agent evaluation scores
- Training data for agent improvement
- Prompt engineering adjustments
- System-wide learning

## üîç Pattern Analysis

### Statistical Methods

1. **Frequency Analysis**: Count occurrences of each failure type
2. **Agent Correlation**: Identify which agents have which failure patterns
3. **Temporal Analysis**: Track failure trends over time
4. **Issue Extraction**: Parse logs and comments for common themes
5. **Confidence Scoring**: Weight patterns by sample size

### Confidence Calculation
```python
confidence = min(1.0, occurrences / 10.0)
```
- Patterns with 10+ occurrences have 100% confidence
- Patterns with fewer occurrences scaled proportionally

## üõ°Ô∏è Security & Privacy

- Uses read-only GitHub API access
- No sensitive data stored in learning files
- PR content summarized, not stored in full
- Review comments truncated to 500 characters
- All data stored in repository (transparent)

## üß™ Testing

Comprehensive test suite in `tests/test_pr_failure_learner.py`:

```bash
# Run all tests
python -m pytest tests/test_pr_failure_learner.py -v

# Run specific test class
python -m pytest tests/test_pr_failure_learner.py::TestPatternAnalysis -v

# Run with coverage
python -m pytest tests/test_pr_failure_learner.py --cov=tools --cov-report=html
```

### Test Coverage

- ‚úÖ Data structure serialization
- ‚úÖ Failure type detection
- ‚úÖ Pattern analysis logic
- ‚úÖ Suggestion generation
- ‚úÖ Agent-specific insights
- ‚úÖ Data persistence
- ‚úÖ GitHub API integration (mocked)
- ‚úÖ Edge cases and error handling

## üîß Configuration

### Environment Variables

- `GITHUB_TOKEN` or `GH_TOKEN`: GitHub API authentication
- `GITHUB_REPOSITORY`: Repository in format `owner/repo`
- `GITHUB_REPOSITORY_OWNER`: Repository owner

### Customization

Edit `tools/pr-failure-learner.py` constants:

```python
DEFAULT_LOOKBACK_DAYS = 30  # Default days to look back
PR_FAILURES_FILE = LEARNINGS_DIR / "pr_failures.json"  # Storage location
```

## üìä Example Output

### Analysis Output
```json
{
  "timestamp": "2025-11-14T03:00:00Z",
  "total_failures": 15,
  "patterns": [
    {
      "pattern_type": "test_failure",
      "occurrences": 8,
      "affected_agents": ["engineer-master", "secure-specialist"],
      "common_issues": [
        "Repeated check failure: pytest (5 times)",
        "Review concern - missing_tests: 3 mentions"
      ],
      "suggested_improvements": [
        "Run tests locally before creating PR",
        "Add comprehensive tests to cover new functionality",
        "Ensure CI environment matches local development"
      ],
      "confidence_score": 0.8
    }
  ],
  "failure_type_distribution": {
    "test_failure": 8,
    "review_rejection": 5,
    "merge_conflict": 2
  }
}
```

### Suggestions Output
```json
{
  "engineer-master": {
    "total_failures": 5,
    "failure_types": {
      "test_failure": 3,
      "review_rejection": 2
    },
    "improvements": [
      "Run tests locally before creating PR",
      "Include comprehensive tests with all PRs",
      "Update documentation for code changes"
    ]
  }
}
```

## üéØ Success Metrics

Track system effectiveness:

1. **Failure Rate Reduction**: % decrease in PR failures over time
2. **Pattern Detection**: Number of actionable patterns identified
3. **Agent Improvement**: Correlation between suggestions and agent scores
4. **Time to Resolution**: Faster fixes after implementing suggestions
5. **Learning Adoption**: Agents incorporating suggestions into code generation

## üöÄ Future Enhancements

Planned improvements:

1. **Temporal Pattern Detection**: Identify time-based failure patterns
2. **Root Cause Analysis**: Deeper analysis of failure chains
3. **Predictive Modeling**: Predict likely failures before PR creation
4. **Auto-Remediation**: Automatically apply simple fixes
5. **Cross-Repository Learning**: Learn from failures across repos
6. **Real-time Feedback**: Provide suggestions during PR creation
7. **A/B Testing**: Test different suggestion strategies

## ü§ù Integration Points

The system integrates with:

- **Agent Registry**: Updates agent metrics with failure insights
- **Learning System**: Contributes to overall learning corpus
- **Evaluation System**: Influences agent performance scoring
- **Workflow Harmonizer**: Coordinates with other automation
- **GitHub Issues**: Creates summary issues for visibility

## üìö Related Systems

- **Agent Metrics Collector** (`tools/agent-metrics-collector.py`)
- **Agent System Registry** (`.github/agent-system/registry.json`)
- **Learning Directory** (`learnings/`)
- **Workflow Failure Handler** (`.github/workflows/workflow-failure-handler.yml`)

## üèÜ Built by @engineer-master

This system embodies **@engineer-master**'s systematic approach to engineering:

- ‚úÖ Rigorous data collection with comprehensive failure categorization
- ‚úÖ Systematic pattern analysis with statistical validation
- ‚úÖ Clear integration with existing agent systems
- ‚úÖ Defensive programming for GitHub API interactions
- ‚úÖ Comprehensive testing of all components
- ‚úÖ Thorough documentation of design and implementation

Following the principles of reliability, innovation, and continuous improvement that define the engineer-master specialization.

---

*Part of the Chained autonomous AI ecosystem*
*Helping AI agents learn from failures to build better code*
